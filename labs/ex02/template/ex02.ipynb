{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    # MSE\n",
    "    pred = tx.dot(w)\n",
    "    loss = 0.5*np.mean((y-pred)**2)\n",
    "    return loss\n",
    "\n",
    "    #MAE\n",
    "    pred = tx.dot(w)\n",
    "    loss = np.mean(np.abs(y-pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    for i in range(len(grid_w0)):\n",
    "        for j in range(len(grid_w1)):\n",
    "            w = np.array((grid_w0[i], grid_w1[j]))\n",
    "            losses[i, j] = compute_loss(y, tx, w)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=42.42448314678248, w0*=66.66666666666669, w1*=16.666666666666686, execution time=0.004 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=10)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    # Compute the MSE loss gradient\n",
    "    N = tx.shape[0]\n",
    "    return -1/N * tx.T.dot(y-tx.dot(w))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        grad = compute_gradient(y, tx, w)\n",
    "        \n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by gradient\n",
    "        # ***************************************************\n",
    "        w = w - gamma * grad\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2792.2367127591674, w0=51.305745401473324, w1=9.435798704492441\n",
      "GD iter. 1/49: loss=265.30246210896615, w0=66.69746902191562, w1=12.266538315840048\n",
      "GD iter. 2/49: loss=37.87837955044177, w0=71.31498610804832, w1=13.115760199244335\n",
      "GD iter. 3/49: loss=17.410212120174524, w0=72.70024123388814, w1=13.370526764265632\n",
      "GD iter. 4/49: loss=15.568077051450457, w0=73.11581777164008, w1=13.446956733772023\n",
      "GD iter. 5/49: loss=15.402284895265295, w0=73.24049073296567, w1=13.469885724623941\n",
      "GD iter. 6/49: loss=15.38736360120863, w0=73.27789262136332, w1=13.476764421879516\n",
      "GD iter. 7/49: loss=15.38602068474353, w0=73.28911318788263, w1=13.478828031056189\n",
      "GD iter. 8/49: loss=15.385899822261674, w0=73.29247935783842, w1=13.47944711380919\n",
      "GD iter. 9/49: loss=15.385888944638305, w0=73.29348920882516, w1=13.47963283863509\n",
      "GD iter. 10/49: loss=15.3858879656522, w0=73.29379216412119, w1=13.479688556082861\n",
      "GD iter. 11/49: loss=15.385887877543453, w0=73.29388305071, w1=13.479705271317192\n",
      "GD iter. 12/49: loss=15.385887869613667, w0=73.29391031668663, w1=13.479710285887492\n",
      "GD iter. 13/49: loss=15.385887868899983, w0=73.29391849647962, w1=13.479711790258582\n",
      "GD iter. 14/49: loss=15.385887868835754, w0=73.29392095041752, w1=13.479712241569908\n",
      "GD iter. 15/49: loss=15.385887868829974, w0=73.29392168659889, w1=13.479712376963306\n",
      "GD iter. 16/49: loss=15.38588786882945, w0=73.2939219074533, w1=13.479712417581325\n",
      "GD iter. 17/49: loss=15.385887868829403, w0=73.29392197370963, w1=13.479712429766732\n",
      "GD iter. 18/49: loss=15.3858878688294, w0=73.29392199358652, w1=13.479712433422353\n",
      "GD iter. 19/49: loss=15.385887868829403, w0=73.29392199954958, w1=13.47971243451904\n",
      "GD iter. 20/49: loss=15.385887868829398, w0=73.2939220013385, w1=13.479712434848047\n",
      "GD iter. 21/49: loss=15.385887868829403, w0=73.29392200187519, w1=13.479712434946748\n",
      "GD iter. 22/49: loss=15.3858878688294, w0=73.29392200203618, w1=13.479712434976358\n",
      "GD iter. 23/49: loss=15.3858878688294, w0=73.29392200208449, w1=13.479712434985242\n",
      "GD iter. 24/49: loss=15.3858878688294, w0=73.29392200209898, w1=13.479712434987906\n",
      "GD iter. 25/49: loss=15.3858878688294, w0=73.29392200210333, w1=13.479712434988706\n",
      "GD iter. 26/49: loss=15.3858878688294, w0=73.29392200210462, w1=13.479712434988945\n",
      "GD iter. 27/49: loss=15.3858878688294, w0=73.29392200210502, w1=13.479712434989018\n",
      "GD iter. 28/49: loss=15.3858878688294, w0=73.29392200210513, w1=13.47971243498904\n",
      "GD iter. 29/49: loss=15.385887868829398, w0=73.29392200210518, w1=13.479712434989047\n",
      "GD iter. 30/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.018 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96025fb894f4313b7804b22e3c814de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    pred = tx @ w\n",
    "    \n",
    "    # 计算误差\n",
    "    error = pred - y\n",
    "    \n",
    "    # 计算梯度\n",
    "    gradient = tx.T @ error / len(y)\n",
    "    \n",
    "    return gradient\n",
    "    \n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        batch_indices = np.random.choice(tx.shape[0], batch_size)\n",
    "        y_batch = y[batch_indices]\n",
    "        tx_batch = tx[batch_indices]\n",
    "\n",
    "        grad = compute_stoch_gradient(y_batch, tx_batch, w)\n",
    "        w = w - gamma * grad\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        losses.append(loss)\n",
    "        ws.append(w)\n",
    "\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=2369.565767676906, w0=6.740637237748628, w1=-3.224180724709384\n",
      "SGD iter. 1/49: loss=1656.3115392262482, w0=16.02218032817574, w1=14.820946325677141\n",
      "SGD iter. 2/49: loss=1372.8999224626086, w0=22.11621878681672, w1=23.271074076528468\n",
      "SGD iter. 3/49: loss=989.4192281493242, w0=29.157949838976105, w1=13.767187262555593\n",
      "SGD iter. 4/49: loss=807.6290997962882, w0=33.49950903158812, w1=14.423704059348186\n",
      "SGD iter. 5/49: loss=670.1270602835862, w0=37.12742553330722, w1=14.690859825663473\n",
      "SGD iter. 6/49: loss=523.9946202516588, w0=41.62895555198573, w1=9.66561169189528\n",
      "SGD iter. 7/49: loss=405.73306797594233, w0=45.37241259099369, w1=14.52070831367331\n",
      "SGD iter. 8/49: loss=349.15131652307855, w0=47.93237731936947, w1=18.411538528242712\n",
      "SGD iter. 9/49: loss=314.7641770173421, w0=50.09360208316298, w1=21.25799849014016\n",
      "SGD iter. 10/49: loss=269.622404961617, w0=52.40402856914153, w1=21.97002376879752\n",
      "SGD iter. 11/49: loss=250.67690821824493, w0=53.721583052541895, w1=22.834154627992238\n",
      "SGD iter. 12/49: loss=242.28352655894727, w0=54.847644753998395, w1=24.134764432338145\n",
      "SGD iter. 13/49: loss=240.42733951862226, w0=55.04738942918695, w1=24.303157005227256\n",
      "SGD iter. 14/49: loss=239.38956296565905, w0=54.59341212540989, w1=23.394261368010685\n",
      "SGD iter. 15/49: loss=170.24047638934917, w0=57.638852077980864, w1=21.518864300193314\n",
      "SGD iter. 16/49: loss=125.74839096539664, w0=59.936207529698706, w1=19.983286088511903\n",
      "SGD iter. 17/49: loss=98.60322721431719, w0=61.733595598508806, w1=19.206276163202308\n",
      "SGD iter. 18/49: loss=81.36180424184639, w0=62.863529595162156, w1=18.29206601543375\n",
      "SGD iter. 19/49: loss=75.84229618359947, w0=63.87421257026199, w1=19.15262093497248\n",
      "SGD iter. 20/49: loss=62.673890689405674, w0=65.00333783503918, w1=18.563236784291092\n",
      "SGD iter. 21/49: loss=60.710751851582295, w0=65.92818173388375, w1=19.51258888545667\n",
      "SGD iter. 22/49: loss=37.16560846576531, w0=67.77762372986952, w1=17.103232072799987\n",
      "SGD iter. 23/49: loss=27.54730669710193, w0=68.97929957217315, w1=15.86861823967712\n",
      "SGD iter. 24/49: loss=26.045929802304435, w0=70.02658029284201, w1=16.742312934875486\n",
      "SGD iter. 25/49: loss=20.068762729819493, w0=70.99908697708416, w1=15.504430175790691\n",
      "SGD iter. 26/49: loss=17.15428852983715, w0=71.8955539748278, w1=14.737237059918458\n",
      "SGD iter. 27/49: loss=17.931677187811655, w0=72.35837895258719, w1=15.533084744255701\n",
      "SGD iter. 28/49: loss=19.0217200532999, w0=71.09015692516779, w1=15.033766441326051\n",
      "SGD iter. 29/49: loss=17.725219246504192, w0=72.24484402913865, w1=15.371298584754896\n",
      "SGD iter. 30/49: loss=16.07963646533854, w0=72.88420051246723, w1=14.58407899277099\n",
      "SGD iter. 31/49: loss=15.902213285512577, w0=74.04489779605804, w1=12.795105839736536\n",
      "SGD iter. 32/49: loss=16.223363689805215, w0=73.69516717828662, w1=12.249284074399633\n",
      "SGD iter. 33/49: loss=15.9771009397968, w0=74.27330058305694, w1=13.007225676330409\n",
      "SGD iter. 34/49: loss=18.289423618876818, w0=75.19747629998972, w1=12.002027578498948\n",
      "SGD iter. 35/49: loss=17.8858278278405, w0=75.05416856894512, w1=12.100795489719882\n",
      "SGD iter. 36/49: loss=19.615863385482378, w0=75.90358503296923, w1=12.195341032844231\n",
      "SGD iter. 37/49: loss=17.789149128269457, w0=74.6139562549125, w1=11.72927474963845\n",
      "SGD iter. 38/49: loss=18.55154439361029, w0=74.84117012047159, w1=11.49544019817944\n",
      "SGD iter. 39/49: loss=18.234046921151542, w0=74.64309071268517, w1=11.51094076335309\n",
      "SGD iter. 40/49: loss=19.15164387377727, w0=74.88266073289776, w1=11.241985629685207\n",
      "SGD iter. 41/49: loss=27.61659011184541, w0=76.66893886418339, w1=9.864374875822572\n",
      "SGD iter. 42/49: loss=27.336720727819543, w0=76.5581666455948, w1=9.840155782671399\n",
      "SGD iter. 43/49: loss=26.974693757195503, w0=77.00020958044354, w1=10.407084217422362\n",
      "SGD iter. 44/49: loss=24.103502979828093, w0=76.33413719337237, w1=10.617489205961371\n",
      "SGD iter. 45/49: loss=24.087807954506694, w0=76.52348511544095, w1=10.838924244252123\n",
      "SGD iter. 46/49: loss=21.42914681377281, w0=75.8648726259899, w1=11.139470827925024\n",
      "SGD iter. 47/49: loss=20.717596855077304, w0=75.17506764563834, w1=10.81049737428074\n",
      "SGD iter. 48/49: loss=18.50945532624598, w0=74.55645954704461, w1=11.3226000451374\n",
      "SGD iter. 49/49: loss=20.418195235999235, w0=75.1563901162565, w1=10.911478166447857\n",
      "SGD: execution time=0.008 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac979cfc3d674066ae286f27d38b4dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "# ***************************************************\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202,), (202, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2869.8351145358524, w0=51.84746409844842, w1=7.7244264061924195\n",
      "GD iter. 1/49: loss=318.2821247015965, w0=67.40170332798297, w1=10.041754328050114\n",
      "GD iter. 2/49: loss=88.6423556165128, w0=72.06797509684336, w1=10.736952704607411\n",
      "GD iter. 3/49: loss=67.97477639885521, w0=73.46785662750146, w1=10.945512217574597\n",
      "GD iter. 4/49: loss=66.11469426926604, w0=73.88782108669889, w1=11.00808007146475\n",
      "GD iter. 5/49: loss=65.94728687760303, w0=74.01381042445813, w1=11.026850427631798\n",
      "GD iter. 6/49: loss=65.93222021235334, w0=74.05160722578589, w1=11.032481534481914\n",
      "GD iter. 7/49: loss=65.93086421248088, w0=74.06294626618423, w1=11.034170866536943\n",
      "GD iter. 8/49: loss=65.93074217249234, w0=74.06634797830372, w1=11.034677666153454\n",
      "GD iter. 9/49: loss=65.93073118889338, w0=74.06736849193958, w1=11.034829706038408\n",
      "GD iter. 10/49: loss=65.93073020036948, w0=74.06767464603033, w1=11.034875318003895\n",
      "GD iter. 11/49: loss=65.93073011140233, w0=74.06776649225755, w1=11.034889001593541\n",
      "GD iter. 12/49: loss=65.93073010339529, w0=74.06779404612573, w1=11.034893106670433\n",
      "GD iter. 13/49: loss=65.93073010267466, w0=74.06780231228618, w1=11.034894338193501\n",
      "GD iter. 14/49: loss=65.93073010260979, w0=74.06780479213431, w1=11.034894707650421\n",
      "GD iter. 15/49: loss=65.93073010260395, w0=74.06780553608874, w1=11.034894818487496\n",
      "GD iter. 16/49: loss=65.93073010260342, w0=74.06780575927507, w1=11.03489485173862\n",
      "GD iter. 17/49: loss=65.93073010260339, w0=74.06780582623098, w1=11.034894861713955\n",
      "GD iter. 18/49: loss=65.93073010260338, w0=74.06780584631775, w1=11.034894864706557\n",
      "GD iter. 19/49: loss=65.93073010260336, w0=74.06780585234378, w1=11.034894865604338\n",
      "GD iter. 20/49: loss=65.93073010260338, w0=74.06780585415159, w1=11.034894865873675\n",
      "GD iter. 21/49: loss=65.93073010260336, w0=74.06780585469393, w1=11.034894865954474\n",
      "GD iter. 22/49: loss=65.93073010260338, w0=74.06780585485663, w1=11.034894865978712\n",
      "GD iter. 23/49: loss=65.93073010260336, w0=74.06780585490544, w1=11.034894865985985\n",
      "GD iter. 24/49: loss=65.93073010260336, w0=74.06780585492008, w1=11.034894865988164\n",
      "GD iter. 25/49: loss=65.93073010260336, w0=74.06780585492449, w1=11.03489486598882\n",
      "GD iter. 26/49: loss=65.93073010260338, w0=74.06780585492581, w1=11.034894865989015\n",
      "GD iter. 27/49: loss=65.93073010260338, w0=74.06780585492619, w1=11.034894865989076\n",
      "GD iter. 28/49: loss=65.93073010260338, w0=74.0678058549263, w1=11.034894865989099\n",
      "GD iter. 29/49: loss=65.93073010260338, w0=74.06780585492635, w1=11.0348948659891\n",
      "GD iter. 30/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 31/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 32/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 33/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 34/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 35/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 36/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 37/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 38/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 39/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 40/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 41/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 42/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 43/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 44/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 45/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 46/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 47/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 48/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 49/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD: execution time=0.002 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\n",
    "#       and the model fit\n",
    "# ***************************************************\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9442eedf324922b4b4d953fb7eee41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = tx @ w\n",
    "    error = pred - y\n",
    "    subgradient = np.sign(error) @ tx /len(y)\n",
    "    return subgradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_mae(y, tx, w):\n",
    "    pred = tx @ w\n",
    "    loss = np.mean(np.abs(y - pred))\n",
    "    return loss\n",
    "\n",
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        subgradient = compute_subgradient_mae(y, tx, w)\n",
    "        loss = compute_loss_mae(y, tx, w)\n",
    "        w = w - gamma * subgradient\n",
    "\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=74.06780585492638, w0=0.7, w1=6.109524327590712e-16\n",
      "SubGD iter. 1/499: loss=73.36780585492637, w0=1.4, w1=1.2219048655181425e-15\n",
      "SubGD iter. 2/499: loss=72.66780585492637, w0=2.0999999999999996, w1=1.832857298277214e-15\n",
      "SubGD iter. 3/499: loss=71.96780585492638, w0=2.8, w1=2.443809731036285e-15\n",
      "SubGD iter. 4/499: loss=71.26780585492638, w0=3.5, w1=3.054762163795356e-15\n",
      "SubGD iter. 5/499: loss=70.56780585492638, w0=4.2, w1=3.665714596554428e-15\n",
      "SubGD iter. 6/499: loss=69.86780585492637, w0=4.9, w1=4.276667029313499e-15\n",
      "SubGD iter. 7/499: loss=69.16780585492639, w0=5.6000000000000005, w1=4.887619462072571e-15\n",
      "SubGD iter. 8/499: loss=68.46780585492637, w0=6.300000000000001, w1=5.498571894831642e-15\n",
      "SubGD iter. 9/499: loss=67.76780585492638, w0=7.000000000000001, w1=6.109524327590714e-15\n",
      "SubGD iter. 10/499: loss=67.06780585492638, w0=7.700000000000001, w1=6.720476760349785e-15\n",
      "SubGD iter. 11/499: loss=66.36780585492637, w0=8.4, w1=7.331429193108857e-15\n",
      "SubGD iter. 12/499: loss=65.66780585492639, w0=9.1, w1=7.942381625867928e-15\n",
      "SubGD iter. 13/499: loss=64.96780585492638, w0=9.799999999999999, w1=8.553334058627e-15\n",
      "SubGD iter. 14/499: loss=64.26780585492638, w0=10.499999999999998, w1=9.164286491386072e-15\n",
      "SubGD iter. 15/499: loss=63.567805854926384, w0=11.199999999999998, w1=9.775238924145143e-15\n",
      "SubGD iter. 16/499: loss=62.867805854926374, w0=11.899999999999997, w1=1.0386191356904215e-14\n",
      "SubGD iter. 17/499: loss=62.167805854926385, w0=12.599999999999996, w1=1.0997143789663286e-14\n",
      "SubGD iter. 18/499: loss=61.46780585492638, w0=13.299999999999995, w1=1.1608096222422358e-14\n",
      "SubGD iter. 19/499: loss=60.76780585492638, w0=13.999999999999995, w1=1.2219048655181429e-14\n",
      "SubGD iter. 20/499: loss=60.067805854926384, w0=14.699999999999994, w1=1.28300010879405e-14\n",
      "SubGD iter. 21/499: loss=59.36780585492639, w0=15.399999999999993, w1=1.3440953520699572e-14\n",
      "SubGD iter. 22/499: loss=58.667805854926385, w0=16.099999999999994, w1=1.4051905953458644e-14\n",
      "SubGD iter. 23/499: loss=57.96780585492638, w0=16.799999999999994, w1=1.4662858386217714e-14\n",
      "SubGD iter. 24/499: loss=57.26780585492638, w0=17.499999999999993, w1=1.5273810818976784e-14\n",
      "SubGD iter. 25/499: loss=56.567805854926384, w0=18.199999999999992, w1=1.5884763251735854e-14\n",
      "SubGD iter. 26/499: loss=55.867805854926395, w0=18.89999999999999, w1=1.6495715684494924e-14\n",
      "SubGD iter. 27/499: loss=55.167805854926385, w0=19.59999999999999, w1=1.7106668117253994e-14\n",
      "SubGD iter. 28/499: loss=54.46780585492638, w0=20.29999999999999, w1=1.7717620550013064e-14\n",
      "SubGD iter. 29/499: loss=53.767805854926394, w0=20.99999999999999, w1=1.8328572982772134e-14\n",
      "SubGD iter. 30/499: loss=53.06780585492639, w0=21.69999999999999, w1=1.8939525415531204e-14\n",
      "SubGD iter. 31/499: loss=52.367805854926395, w0=22.399999999999988, w1=1.9550477848290273e-14\n",
      "SubGD iter. 32/499: loss=51.667805854926385, w0=23.099999999999987, w1=2.0161430281049343e-14\n",
      "SubGD iter. 33/499: loss=50.96780585492639, w0=23.799999999999986, w1=2.0772382713808413e-14\n",
      "SubGD iter. 34/499: loss=50.267805854926394, w0=24.499999999999986, w1=2.1383335146567483e-14\n",
      "SubGD iter. 35/499: loss=49.56780585492639, w0=25.199999999999985, w1=2.1994287579326553e-14\n",
      "SubGD iter. 36/499: loss=48.867805854926395, w0=25.899999999999984, w1=2.2605240012085623e-14\n",
      "SubGD iter. 37/499: loss=48.1678058549264, w0=26.599999999999984, w1=2.3216192444844693e-14\n",
      "SubGD iter. 38/499: loss=47.4678058549264, w0=27.299999999999983, w1=2.3827144877603763e-14\n",
      "SubGD iter. 39/499: loss=46.7678058549264, w0=27.999999999999982, w1=2.4438097310362833e-14\n",
      "SubGD iter. 40/499: loss=46.067805854926405, w0=28.69999999999998, w1=2.5049049743121903e-14\n",
      "SubGD iter. 41/499: loss=45.367805854926395, w0=29.39999999999998, w1=2.5660002175880973e-14\n",
      "SubGD iter. 42/499: loss=44.6678058549264, w0=30.09999999999998, w1=2.6270954608640043e-14\n",
      "SubGD iter. 43/499: loss=43.9678058549264, w0=30.79999999999998, w1=2.6881907041399113e-14\n",
      "SubGD iter. 44/499: loss=43.2678058549264, w0=31.49999999999998, w1=2.7492859474158183e-14\n",
      "SubGD iter. 45/499: loss=42.567805854926405, w0=32.19999999999998, w1=2.8103811906917253e-14\n",
      "SubGD iter. 46/499: loss=41.867805854926395, w0=32.899999999999984, w1=2.871476433967632e-14\n",
      "SubGD iter. 47/499: loss=41.167805854926385, w0=33.59999999999999, w1=2.9325716772435396e-14\n",
      "SubGD iter. 48/499: loss=40.46780585492639, w0=34.29999999999999, w1=2.993666920519447e-14\n",
      "SubGD iter. 49/499: loss=39.767805854926394, w0=34.99999999999999, w1=3.054762163795354e-14\n",
      "SubGD iter. 50/499: loss=39.067805854926384, w0=35.699999999999996, w1=3.1158574070712615e-14\n",
      "SubGD iter. 51/499: loss=38.36780585492638, w0=36.4, w1=3.176952650347169e-14\n",
      "SubGD iter. 52/499: loss=37.66780585492638, w0=37.1, w1=3.238047893623076e-14\n",
      "SubGD iter. 53/499: loss=36.96780585492638, w0=37.800000000000004, w1=3.2991431368989835e-14\n",
      "SubGD iter. 54/499: loss=36.26780585492637, w0=38.50000000000001, w1=3.360238380174891e-14\n",
      "SubGD iter. 55/499: loss=35.56780585492637, w0=39.20000000000001, w1=3.421333623450798e-14\n",
      "SubGD iter. 56/499: loss=34.86780585492637, w0=39.90000000000001, w1=3.4824288667267054e-14\n",
      "SubGD iter. 57/499: loss=34.16780585492637, w0=40.600000000000016, w1=3.543524110002613e-14\n",
      "SubGD iter. 58/499: loss=33.46780585492636, w0=41.30000000000002, w1=3.60461935327852e-14\n",
      "SubGD iter. 59/499: loss=32.767805854926365, w0=42.00000000000002, w1=3.6657145965544273e-14\n",
      "SubGD iter. 60/499: loss=32.067805854926355, w0=42.700000000000024, w1=3.7268098398303347e-14\n",
      "SubGD iter. 61/499: loss=31.36780585492636, w0=43.40000000000003, w1=3.787905083106242e-14\n",
      "SubGD iter. 62/499: loss=30.66780585492635, w0=44.10000000000003, w1=3.849000326382149e-14\n",
      "SubGD iter. 63/499: loss=29.967805854926347, w0=44.80000000000003, w1=3.9100955696580566e-14\n",
      "SubGD iter. 64/499: loss=29.267805854926348, w0=45.500000000000036, w1=3.971190812933964e-14\n",
      "SubGD iter. 65/499: loss=28.567805854926345, w0=46.20000000000004, w1=4.032286056209871e-14\n",
      "SubGD iter. 66/499: loss=27.867805854926342, w0=46.90000000000004, w1=4.0933812994857785e-14\n",
      "SubGD iter. 67/499: loss=27.17327020966892, w0=47.59306930693074, w1=0.011147845678271063\n",
      "SubGD iter. 68/499: loss=26.490451563751197, w0=48.279207920792125, w1=0.03308574108989941\n",
      "SubGD iter. 69/499: loss=25.81721232277017, w0=48.96534653465351, w1=0.05502363650152776\n",
      "SubGD iter. 70/499: loss=25.15503943465645, w0=49.63069306930698, w1=0.10538326388307814\n",
      "SubGD iter. 71/499: loss=24.524103413894778, w0=50.28910891089114, w1=0.16746568532793435\n",
      "SubGD iter. 72/499: loss=23.899295346035593, w0=50.947524752475296, w1=0.22954810677279056\n",
      "SubGD iter. 73/499: loss=23.284392925657144, w0=51.59207920792084, w1=0.31242512932747524\n",
      "SubGD iter. 74/499: loss=22.686876444181845, w0=52.22277227722777, w1=0.4119501328839991\n",
      "SubGD iter. 75/499: loss=22.10626756964055, w0=52.84653465346539, w1=0.5208167847923756\n",
      "SubGD iter. 76/499: loss=21.537818828008433, w0=53.4564356435644, w1=0.6457900912635992\n",
      "SubGD iter. 77/499: loss=20.986339874628463, w0=54.0594059405941, w1=0.7796904498577214\n",
      "SubGD iter. 78/499: loss=20.445560936620446, w0=54.655445544554496, w1=0.9197570104995693\n",
      "SubGD iter. 79/499: loss=19.91191015895785, w0=55.24455445544559, w1=1.0670920297849913\n",
      "SubGD iter. 80/499: loss=19.389644090563234, w0=55.819801980198065, w1=1.2261255948210765\n",
      "SubGD iter. 81/499: loss=18.887989064395885, w0=56.36732673267331, w1=1.410709342622213\n",
      "SubGD iter. 82/499: loss=18.415960501854236, w0=56.900990099009945, w1=1.605853732220269\n",
      "SubGD iter. 83/499: loss=17.954898543040386, w0=57.42772277227727, w1=1.808762802293962\n",
      "SubGD iter. 84/499: loss=17.505757656579824, w0=57.933663366336674, w1=2.0285064197514697\n",
      "SubGD iter. 85/499: loss=17.07495742693161, w0=58.43267326732677, w1=2.2494370848672776\n",
      "SubGD iter. 86/499: loss=16.652967297509903, w0=58.91089108910895, w1=2.4837982986028337\n",
      "SubGD iter. 87/499: loss=16.24854073149673, w0=59.382178217821824, w1=2.7260245553531504\n",
      "SubGD iter. 88/499: loss=15.849105212654159, w0=59.83960396039608, w1=2.978742333469136\n",
      "SubGD iter. 89/499: loss=15.46691979123133, w0=60.262376237623805, w1=3.251528669355438\n",
      "SubGD iter. 90/499: loss=15.108294621512215, w0=60.67821782178222, w1=3.5270865794242794\n",
      "SubGD iter. 91/499: loss=14.754896345922832, w0=61.087128712871326, w1=3.806459183951815\n",
      "SubGD iter. 92/499: loss=14.40452896162028, w0=61.49603960396043, w1=4.085831788479351\n",
      "SubGD iter. 93/499: loss=14.055787028127279, w0=61.891089108910926, w1=4.373839384328607\n",
      "SubGD iter. 94/499: loss=13.714620911605635, w0=62.27920792079211, w1=4.666037469532047\n",
      "SubGD iter. 95/499: loss=13.381236307284155, w0=62.65346534653469, w1=4.959829093241769\n",
      "SubGD iter. 96/499: loss=13.058821615166238, w0=63.02079207920796, w1=5.25705719205664\n",
      "SubGD iter. 97/499: loss=12.74025172433924, w0=63.38118811881192, w1=5.560434316352406\n",
      "SubGD iter. 98/499: loss=12.42321888875611, w0=63.74158415841588, w1=5.863811440648173\n",
      "SubGD iter. 99/499: loss=12.107561731901173, w0=64.08811881188123, w1=6.172402175278548\n",
      "SubGD iter. 100/499: loss=11.800622097398135, w0=64.42772277227726, w1=6.486369310516498\n",
      "SubGD iter. 101/499: loss=11.495041794646427, w0=64.7673267326733, w1=6.800336445754448\n",
      "SubGD iter. 102/499: loss=11.189461491894715, w0=65.10693069306933, w1=7.114303580992399\n",
      "SubGD iter. 103/499: loss=10.883881189143004, w0=65.44653465346536, w1=7.428270716230349\n",
      "SubGD iter. 104/499: loss=10.584593408313202, w0=65.76534653465349, w1=7.747893210218626\n",
      "SubGD iter. 105/499: loss=10.295816534318941, w0=66.070297029703, w1=8.073669686866905\n",
      "SubGD iter. 106/499: loss=10.01135208122136, w0=66.37524752475251, w1=8.399446163515185\n",
      "SubGD iter. 107/499: loss=9.72808432666813, w0=66.6663366336634, w1=8.73297028041739\n",
      "SubGD iter. 108/499: loss=9.44812546112251, w0=66.9574257425743, w1=9.066494397319596\n",
      "SubGD iter. 109/499: loss=9.17104110409667, w0=67.23465346534658, w1=9.39863031947029\n",
      "SubGD iter. 110/499: loss=8.903656131158963, w0=67.51188118811886, w1=9.730766241620982\n",
      "SubGD iter. 111/499: loss=8.636271158221255, w0=67.78910891089114, w1=10.062902163771675\n",
      "SubGD iter. 112/499: loss=8.376151920302375, w0=68.06633663366343, w1=10.363999289979422\n",
      "SubGD iter. 113/499: loss=8.140540838751498, w0=68.32970297029709, w1=10.660466909273612\n",
      "SubGD iter. 114/499: loss=7.918544501597273, w0=68.59306930693076, w1=10.943174379960814\n",
      "SubGD iter. 115/499: loss=7.705279728377, w0=68.85643564356442, w1=11.225881850648015\n",
      "SubGD iter. 116/499: loss=7.493695831178641, w0=69.11287128712878, w1=11.504395843582206\n",
      "SubGD iter. 117/499: loss=7.289992405743416, w0=69.35544554455453, w1=11.78820189306775\n",
      "SubGD iter. 118/499: loss=7.097234035781543, w0=69.58415841584166, w1=12.060911465190971\n",
      "SubGD iter. 119/499: loss=6.919905294668923, w0=69.80594059405948, w1=12.324245668386048\n",
      "SubGD iter. 120/499: loss=6.750573527315454, w0=70.0277227722773, w1=12.587579871581125\n",
      "SubGD iter. 121/499: loss=6.584744810805664, w0=70.25643564356443, w1=12.824765405096484\n",
      "SubGD iter. 122/499: loss=6.430343276347806, w0=70.47821782178225, w1=13.065616959310148\n",
      "SubGD iter. 123/499: loss=6.278071481890353, w0=70.69306930693077, w1=13.302953389983912\n",
      "SubGD iter. 124/499: loss=6.133663329263324, w0=70.89405940594067, w1=13.525403099312918\n",
      "SubGD iter. 125/499: loss=6.00584079834303, w0=71.08811881188126, w1=13.742945617944212\n",
      "SubGD iter. 126/499: loss=5.885021825223219, w0=71.27524752475254, w1=13.953548196006844\n",
      "SubGD iter. 127/499: loss=5.771635252269659, w0=71.46237623762383, w1=14.164150774069476\n",
      "SubGD iter. 128/499: loss=5.667162061790258, w0=71.62178217821788, w1=14.349779559473173\n",
      "SubGD iter. 129/499: loss=5.586726765993146, w0=71.75346534653471, w1=14.51689010761231\n",
      "SubGD iter. 130/499: loss=5.523847812160388, w0=71.87128712871292, w1=14.670791185324186\n",
      "SubGD iter. 131/499: loss=5.480093708591872, w0=71.95445544554461, w1=14.780276456654521\n",
      "SubGD iter. 132/499: loss=5.4530880035020255, w0=72.0376237623763, w1=14.889761727984856\n",
      "SubGD iter. 133/499: loss=5.427392630862905, w0=72.10693069306937, w1=14.985916181776727\n",
      "SubGD iter. 134/499: loss=5.407322445682752, w0=72.17623762376245, w1=15.082070635568597\n",
      "SubGD iter. 135/499: loss=5.387252260502599, w0=72.24554455445552, w1=15.178225089360467\n",
      "SubGD iter. 136/499: loss=5.3704607803386955, w0=72.30099009900998, w1=15.25972348971591\n",
      "SubGD iter. 137/499: loss=5.357406523334741, w0=72.34950495049513, w1=15.335091856448138\n",
      "SubGD iter. 138/499: loss=5.345929264022583, w0=72.39801980198028, w1=15.410460223180365\n",
      "SubGD iter. 139/499: loss=5.335714659517474, w0=72.43267326732682, w1=15.469961786755725\n",
      "SubGD iter. 140/499: loss=5.330043910465361, w0=72.46039603960405, w1=15.51864528583281\n",
      "SubGD iter. 141/499: loss=5.325676428273225, w0=72.48811881188128, w1=15.561592159086487\n",
      "SubGD iter. 142/499: loss=5.322176726526591, w0=72.5019801980199, w1=15.597828332032526\n",
      "SubGD iter. 143/499: loss=5.320111309643112, w0=72.52277227722782, w1=15.624722856626713\n",
      "SubGD iter. 144/499: loss=5.318478284898438, w0=72.55049504950505, w1=15.642690329098\n",
      "SubGD iter. 145/499: loss=5.3172400485651465, w0=72.56435643564366, w1=15.664356578291091\n",
      "SubGD iter. 146/499: loss=5.316406547951546, w0=72.58514851485158, w1=15.677095775361284\n",
      "SubGD iter. 147/499: loss=5.315557122666144, w0=72.6059405940595, w1=15.689834972431477\n",
      "SubGD iter. 148/499: loss=5.314707697380741, w0=72.62673267326743, w1=15.70257416950167\n",
      "SubGD iter. 149/499: loss=5.313876880922167, w0=72.64059405940604, w1=15.72424041869476\n",
      "SubGD iter. 150/499: loss=5.313052246871384, w0=72.66138613861396, w1=15.736979615764954\n",
      "SubGD iter. 151/499: loss=5.312377839024387, w0=72.66831683168327, w1=15.74811029423128\n",
      "SubGD iter. 152/499: loss=5.312132229725043, w0=72.67524752475258, w1=15.759240972697606\n",
      "SubGD iter. 153/499: loss=5.311886620425697, w0=72.68217821782189, w1=15.770371651163932\n",
      "SubGD iter. 154/499: loss=5.311683566098434, w0=72.68217821782189, w1=15.774323911906686\n",
      "SubGD iter. 155/499: loss=5.311661251291322, w0=72.68217821782189, w1=15.77827617264944\n",
      "SubGD iter. 156/499: loss=5.31163893648421, w0=72.68217821782189, w1=15.782228433392193\n",
      "SubGD iter. 157/499: loss=5.311616621677096, w0=72.68217821782189, w1=15.786180694134947\n",
      "SubGD iter. 158/499: loss=5.311594306869984, w0=72.68217821782189, w1=15.7901329548777\n",
      "SubGD iter. 159/499: loss=5.311571992062871, w0=72.68217821782189, w1=15.794085215620454\n",
      "SubGD iter. 160/499: loss=5.31154967725576, w0=72.68217821782189, w1=15.798037476363207\n",
      "SubGD iter. 161/499: loss=5.311527362448647, w0=72.68217821782189, w1=15.801989737105961\n",
      "SubGD iter. 162/499: loss=5.311505047641535, w0=72.68217821782189, w1=15.805941997848715\n",
      "SubGD iter. 163/499: loss=5.311482732834422, w0=72.68217821782189, w1=15.809894258591468\n",
      "SubGD iter. 164/499: loss=5.311460418027309, w0=72.68217821782189, w1=15.813846519334222\n",
      "SubGD iter. 165/499: loss=5.311438103220198, w0=72.68217821782189, w1=15.817798780076975\n",
      "SubGD iter. 166/499: loss=5.311415788413085, w0=72.68217821782189, w1=15.821751040819729\n",
      "SubGD iter. 167/499: loss=5.311393473605974, w0=72.68217821782189, w1=15.825703301562482\n",
      "SubGD iter. 168/499: loss=5.31137115879886, w0=72.68217821782189, w1=15.829655562305236\n",
      "SubGD iter. 169/499: loss=5.3113488439917464, w0=72.68217821782189, w1=15.83360782304799\n",
      "SubGD iter. 170/499: loss=5.311326529184636, w0=72.68217821782189, w1=15.837560083790743\n",
      "SubGD iter. 171/499: loss=5.311304214377523, w0=72.68217821782189, w1=15.841512344533497\n",
      "SubGD iter. 172/499: loss=5.311281899570409, w0=72.68217821782189, w1=15.84546460527625\n",
      "SubGD iter. 173/499: loss=5.311259584763298, w0=72.68217821782189, w1=15.849416866019004\n",
      "SubGD iter. 174/499: loss=5.311237269956186, w0=72.68217821782189, w1=15.853369126761757\n",
      "SubGD iter. 175/499: loss=5.311214955149072, w0=72.68217821782189, w1=15.857321387504511\n",
      "SubGD iter. 176/499: loss=5.31119264034196, w0=72.68217821782189, w1=15.861273648247264\n",
      "SubGD iter. 177/499: loss=5.311170325534848, w0=72.68217821782189, w1=15.865225908990018\n",
      "SubGD iter. 178/499: loss=5.311148010727736, w0=72.68217821782189, w1=15.869178169732772\n",
      "SubGD iter. 179/499: loss=5.311125695920623, w0=72.68217821782189, w1=15.873130430475525\n",
      "SubGD iter. 180/499: loss=5.31110338111351, w0=72.68217821782189, w1=15.877082691218279\n",
      "SubGD iter. 181/499: loss=5.311081066306398, w0=72.68217821782189, w1=15.881034951961032\n",
      "SubGD iter. 182/499: loss=5.311058751499285, w0=72.68217821782189, w1=15.884987212703786\n",
      "SubGD iter. 183/499: loss=5.3110364366921745, w0=72.68217821782189, w1=15.88893947344654\n",
      "SubGD iter. 184/499: loss=5.311014121885061, w0=72.68217821782189, w1=15.892891734189293\n",
      "SubGD iter. 185/499: loss=5.310991807077948, w0=72.68217821782189, w1=15.896843994932047\n",
      "SubGD iter. 186/499: loss=5.310969492270837, w0=72.68217821782189, w1=15.9007962556748\n",
      "SubGD iter. 187/499: loss=5.310947177463723, w0=72.68217821782189, w1=15.904748516417554\n",
      "SubGD iter. 188/499: loss=5.31092486265661, w0=72.68217821782189, w1=15.908700777160307\n",
      "SubGD iter. 189/499: loss=5.310902547849499, w0=72.68217821782189, w1=15.91265303790306\n",
      "SubGD iter. 190/499: loss=5.310913706061381, w0=72.67524752475258, w1=15.910526938117323\n",
      "SubGD iter. 191/499: loss=5.31089223718627, w0=72.67524752475258, w1=15.914479198860077\n",
      "SubGD iter. 192/499: loss=5.3108699223791564, w0=72.67524752475258, w1=15.91843145960283\n",
      "SubGD iter. 193/499: loss=5.310862636053835, w0=72.66831683168327, w1=15.916305359817093\n",
      "SubGD iter. 194/499: loss=5.310859611715927, w0=72.66831683168327, w1=15.920257620559847\n",
      "SubGD iter. 195/499: loss=5.310837296908816, w0=72.66831683168327, w1=15.9242098813026\n",
      "SubGD iter. 196/499: loss=5.310814982101703, w0=72.66831683168327, w1=15.928162142045354\n",
      "SubGD iter. 197/499: loss=5.310823570190169, w0=72.66138613861396, w1=15.926036042259616\n",
      "SubGD iter. 198/499: loss=5.310804671438475, w0=72.66138613861396, w1=15.92998830300237\n",
      "SubGD iter. 199/499: loss=5.3107823566313614, w0=72.66138613861396, w1=15.933940563745123\n",
      "SubGD iter. 200/499: loss=5.310772500182623, w0=72.65445544554466, w1=15.931814463959386\n",
      "SubGD iter. 201/499: loss=5.3107720459681325, w0=72.65445544554466, w1=15.93576672470214\n",
      "SubGD iter. 202/499: loss=5.310749731161019, w0=72.65445544554466, w1=15.939718985444893\n",
      "SubGD iter. 203/499: loss=5.310727416353908, w0=72.65445544554466, w1=15.943671246187646\n",
      "SubGD iter. 204/499: loss=5.310733434318959, w0=72.64752475247535, w1=15.941545146401909\n",
      "SubGD iter. 205/499: loss=5.310717105690678, w0=72.64752475247535, w1=15.945497407144662\n",
      "SubGD iter. 206/499: loss=5.3106947908835656, w0=72.64752475247535, w1=15.949449667887416\n",
      "SubGD iter. 207/499: loss=5.310682364311412, w0=72.64059405940604, w1=15.947323568101679\n",
      "SubGD iter. 208/499: loss=5.310684480220337, w0=72.64059405940604, w1=15.951275828844432\n",
      "SubGD iter. 209/499: loss=5.310662165413224, w0=72.64059405940604, w1=15.955228089587186\n",
      "SubGD iter. 210/499: loss=5.310639850606112, w0=72.64059405940604, w1=15.95918035032994\n",
      "SubGD iter. 211/499: loss=5.310643298447746, w0=72.63366336633673, w1=15.957054250544202\n",
      "SubGD iter. 212/499: loss=5.310629539942882, w0=72.63366336633673, w1=15.961006511286955\n",
      "SubGD iter. 213/499: loss=5.3106072251357705, w0=72.63366336633673, w1=15.964958772029709\n",
      "SubGD iter. 214/499: loss=5.310592228440201, w0=72.62673267326743, w1=15.962832672243971\n",
      "SubGD iter. 215/499: loss=5.310633183099028, w0=72.63366336633673, w1=15.967301372051375\n",
      "SubGD iter. 216/499: loss=5.310599343585063, w0=72.62673267326743, w1=15.965175272265638\n",
      "SubGD iter. 217/499: loss=5.31061822827579, w0=72.63366336633673, w1=15.969643972073042\n",
      "SubGD iter. 218/499: loss=5.310606458729926, w0=72.62673267326743, w1=15.967517872287305\n",
      "SubGD iter. 219/499: loss=5.3106032734525535, w0=72.63366336633673, w1=15.971986572094709\n",
      "SubGD iter. 220/499: loss=5.3106135738747895, w0=72.62673267326743, w1=15.969860472308971\n",
      "SubGD iter. 221/499: loss=5.310588318629316, w0=72.63366336633673, w1=15.974329172116375\n",
      "SubGD iter. 222/499: loss=5.310620689019651, w0=72.62673267326743, w1=15.972203072330638\n",
      "SubGD iter. 223/499: loss=5.310574966149887, w0=72.62673267326743, w1=15.970593411609551\n",
      "SubGD iter. 224/499: loss=5.310583639649728, w0=72.63366336633673, w1=15.975062111416955\n",
      "SubGD iter. 225/499: loss=5.310622915165495, w0=72.62673267326743, w1=15.972936011631218\n",
      "SubGD iter. 226/499: loss=5.310576651555033, w0=72.62673267326743, w1=15.97132635091013\n",
      "SubGD iter. 227/499: loss=5.31057896067014, w0=72.63366336633673, w1=15.975795050717535\n",
      "SubGD iter. 228/499: loss=5.310625141311338, w0=72.62673267326743, w1=15.973668950931797\n",
      "SubGD iter. 229/499: loss=5.310578336960181, w0=72.62673267326743, w1=15.97205929021071\n",
      "SubGD iter. 230/499: loss=5.310574635520699, w0=72.62673267326743, w1=15.970449629489623\n",
      "SubGD iter. 231/499: loss=5.310584557534204, w0=72.63366336633673, w1=15.974918329297028\n",
      "SubGD iter. 232/499: loss=5.31062247845816, w0=72.62673267326743, w1=15.97279222951129\n",
      "SubGD iter. 233/499: loss=5.310576320925847, w0=72.62673267326743, w1=15.971182568790203\n",
      "SubGD iter. 234/499: loss=5.3105798785546146, w0=72.63366336633673, w1=15.975651268597607\n",
      "SubGD iter. 235/499: loss=5.310624704604003, w0=72.62673267326743, w1=15.97352516881187\n",
      "SubGD iter. 236/499: loss=5.310578006330994, w0=72.62673267326743, w1=15.971915508090783\n",
      "SubGD iter. 237/499: loss=5.310575199575027, w0=72.63366336633673, w1=15.976384207898187\n",
      "SubGD iter. 238/499: loss=5.310626930749845, w0=72.62673267326743, w1=15.97425810811245\n",
      "SubGD iter. 239/499: loss=5.310579691736141, w0=72.62673267326743, w1=15.972648447391363\n",
      "SubGD iter. 240/499: loss=5.310575990296659, w0=72.62673267326743, w1=15.971038786670276\n",
      "SubGD iter. 241/499: loss=5.310580796439089, w0=72.63366336633673, w1=15.97550748647768\n",
      "SubGD iter. 242/499: loss=5.310624267896667, w0=72.62673267326743, w1=15.973381386691942\n",
      "SubGD iter. 243/499: loss=5.310577675701806, w0=72.62673267326743, w1=15.971771725970855\n",
      "SubGD iter. 244/499: loss=5.310576117459501, w0=72.63366336633673, w1=15.97624042577826\n",
      "SubGD iter. 245/499: loss=5.31062649404251, w0=72.62673267326743, w1=15.974114325992522\n",
      "SubGD iter. 246/499: loss=5.310579361106954, w0=72.62673267326743, w1=15.972504665271435\n",
      "SubGD iter. 247/499: loss=5.310575659667472, w0=72.62673267326743, w1=15.970895004550348\n",
      "SubGD iter. 248/499: loss=5.310581714323563, w0=72.63366336633673, w1=15.975363704357752\n",
      "SubGD iter. 249/499: loss=5.310623831189332, w0=72.62673267326743, w1=15.973237604572015\n",
      "SubGD iter. 250/499: loss=5.31057734507262, w0=72.62673267326743, w1=15.971627943850928\n",
      "SubGD iter. 251/499: loss=5.310577035343975, w0=72.63366336633673, w1=15.976096643658332\n",
      "SubGD iter. 252/499: loss=5.310626057335176, w0=72.62673267326743, w1=15.973970543872595\n",
      "SubGD iter. 253/499: loss=5.310579030477766, w0=72.62673267326743, w1=15.972360883151508\n",
      "SubGD iter. 254/499: loss=5.3105753290382856, w0=72.62673267326743, w1=15.97075122243042\n",
      "SubGD iter. 255/499: loss=5.310582632208036, w0=72.63366336633673, w1=15.975219922237825\n",
      "SubGD iter. 256/499: loss=5.310623394481998, w0=72.62673267326743, w1=15.973093822452087\n",
      "SubGD iter. 257/499: loss=5.3105770144434326, w0=72.62673267326743, w1=15.971484161731\n",
      "SubGD iter. 258/499: loss=5.3105779532284485, w0=72.63366336633673, w1=15.975952861538405\n",
      "SubGD iter. 259/499: loss=5.3106256206278415, w0=72.62673267326743, w1=15.973826761752667\n",
      "SubGD iter. 260/499: loss=5.31057869984858, w0=72.62673267326743, w1=15.97221710103158\n",
      "SubGD iter. 261/499: loss=5.310574998409098, w0=72.62673267326743, w1=15.970607440310493\n",
      "SubGD iter. 262/499: loss=5.3105835500925105, w0=72.63366336633673, w1=15.975076140117897\n",
      "SubGD iter. 263/499: loss=5.3106229577746635, w0=72.62673267326743, w1=15.97295004033216\n",
      "SubGD iter. 264/499: loss=5.310576683814246, w0=72.62673267326743, w1=15.971340379611073\n",
      "SubGD iter. 265/499: loss=5.310578871112924, w0=72.63366336633673, w1=15.975809079418477\n",
      "SubGD iter. 266/499: loss=5.310625183920507, w0=72.62673267326743, w1=15.97368297963274\n",
      "SubGD iter. 267/499: loss=5.310578369219393, w0=72.62673267326743, w1=15.972073318911653\n",
      "SubGD iter. 268/499: loss=5.310574667779911, w0=72.62673267326743, w1=15.970463658190566\n",
      "SubGD iter. 269/499: loss=5.310584467976984, w0=72.63366336633673, w1=15.97493235799797\n",
      "SubGD iter. 270/499: loss=5.310622521067329, w0=72.62673267326743, w1=15.972806258212232\n",
      "SubGD iter. 271/499: loss=5.310576353185058, w0=72.62673267326743, w1=15.971196597491145\n",
      "SubGD iter. 272/499: loss=5.310579788997396, w0=72.63366336633673, w1=15.97566529729855\n",
      "SubGD iter. 273/499: loss=5.310624747213171, w0=72.62673267326743, w1=15.973539197512812\n",
      "SubGD iter. 274/499: loss=5.310578038590206, w0=72.62673267326743, w1=15.971929536791725\n",
      "SubGD iter. 275/499: loss=5.310575110017808, w0=72.63366336633673, w1=15.97639823659913\n",
      "SubGD iter. 276/499: loss=5.310626973359014, w0=72.62673267326743, w1=15.974272136813392\n",
      "SubGD iter. 277/499: loss=5.310579723995353, w0=72.62673267326743, w1=15.972662476092305\n",
      "SubGD iter. 278/499: loss=5.310576022555872, w0=72.62673267326743, w1=15.971052815371218\n",
      "SubGD iter. 279/499: loss=5.31058070688187, w0=72.63366336633673, w1=15.975521515178622\n",
      "SubGD iter. 280/499: loss=5.310624310505837, w0=72.62673267326743, w1=15.973395415392885\n",
      "SubGD iter. 281/499: loss=5.310577707961019, w0=72.62673267326743, w1=15.971785754671798\n",
      "SubGD iter. 282/499: loss=5.310576027902282, w0=72.63366336633673, w1=15.976254454479202\n",
      "SubGD iter. 283/499: loss=5.31062653665168, w0=72.62673267326743, w1=15.974128354693464\n",
      "SubGD iter. 284/499: loss=5.310579393366166, w0=72.62673267326743, w1=15.972518693972377\n",
      "SubGD iter. 285/499: loss=5.310575691926684, w0=72.62673267326743, w1=15.97090903325129\n",
      "SubGD iter. 286/499: loss=5.3105816247663435, w0=72.63366336633673, w1=15.975377733058695\n",
      "SubGD iter. 287/499: loss=5.310623873798502, w0=72.62673267326743, w1=15.973251633272957\n",
      "SubGD iter. 288/499: loss=5.310577377331832, w0=72.62673267326743, w1=15.97164197255187\n",
      "SubGD iter. 289/499: loss=5.310576945786757, w0=72.63366336633673, w1=15.976110672359274\n",
      "SubGD iter. 290/499: loss=5.3106260999443435, w0=72.62673267326743, w1=15.973984572573537\n",
      "SubGD iter. 291/499: loss=5.310579062736979, w0=72.62673267326743, w1=15.97237491185245\n",
      "SubGD iter. 292/499: loss=5.310575361297499, w0=72.62673267326743, w1=15.970765251131363\n",
      "SubGD iter. 293/499: loss=5.310582542650818, w0=72.63366336633673, w1=15.975233950938767\n",
      "SubGD iter. 294/499: loss=5.310623437091167, w0=72.62673267326743, w1=15.97310785115303\n",
      "SubGD iter. 295/499: loss=5.310577046702645, w0=72.62673267326743, w1=15.971498190431943\n",
      "SubGD iter. 296/499: loss=5.31057786367123, w0=72.63366336633673, w1=15.975966890239347\n",
      "SubGD iter. 297/499: loss=5.310625663237009, w0=72.62673267326743, w1=15.97384079045361\n",
      "SubGD iter. 298/499: loss=5.310578732107792, w0=72.62673267326743, w1=15.972231129732522\n",
      "SubGD iter. 299/499: loss=5.310575030668311, w0=72.62673267326743, w1=15.970621469011435\n",
      "SubGD iter. 300/499: loss=5.31058346053529, w0=72.63366336633673, w1=15.97509016881884\n",
      "SubGD iter. 301/499: loss=5.310623000383831, w0=72.62673267326743, w1=15.972964069033102\n",
      "SubGD iter. 302/499: loss=5.3105767160734585, w0=72.62673267326743, w1=15.971354408312015\n",
      "SubGD iter. 303/499: loss=5.310578781555702, w0=72.63366336633673, w1=15.97582310811942\n",
      "SubGD iter. 304/499: loss=5.310625226529674, w0=72.62673267326743, w1=15.973697008333682\n",
      "SubGD iter. 305/499: loss=5.3105784014786055, w0=72.62673267326743, w1=15.972087347612595\n",
      "SubGD iter. 306/499: loss=5.3105747000391235, w0=72.62673267326743, w1=15.970477686891508\n",
      "SubGD iter. 307/499: loss=5.310584378419766, w0=72.63366336633673, w1=15.974946386698912\n",
      "SubGD iter. 308/499: loss=5.310622563676496, w0=72.62673267326743, w1=15.972820286913175\n",
      "SubGD iter. 309/499: loss=5.3105763854442705, w0=72.62673267326743, w1=15.971210626192088\n",
      "SubGD iter. 310/499: loss=5.310579699440178, w0=72.63366336633673, w1=15.975679325999492\n",
      "SubGD iter. 311/499: loss=5.31062478982234, w0=72.62673267326743, w1=15.973553226213754\n",
      "SubGD iter. 312/499: loss=5.310578070849419, w0=72.62673267326743, w1=15.971943565492667\n",
      "SubGD iter. 313/499: loss=5.310575020460591, w0=72.63366336633673, w1=15.976412265300072\n",
      "SubGD iter. 314/499: loss=5.3106270159681825, w0=72.62673267326743, w1=15.974286165514334\n",
      "SubGD iter. 315/499: loss=5.310579756254565, w0=72.62673267326743, w1=15.972676504793247\n",
      "SubGD iter. 316/499: loss=5.310576054815085, w0=72.62673267326743, w1=15.97106684407216\n",
      "SubGD iter. 317/499: loss=5.310580617324651, w0=72.63366336633673, w1=15.975535543879564\n",
      "SubGD iter. 318/499: loss=5.3106243531150055, w0=72.62673267326743, w1=15.973409444093827\n",
      "SubGD iter. 319/499: loss=5.310577740220231, w0=72.62673267326743, w1=15.97179978337274\n",
      "SubGD iter. 320/499: loss=5.310575938345063, w0=72.63366336633673, w1=15.976268483180144\n",
      "SubGD iter. 321/499: loss=5.310626579260847, w0=72.62673267326743, w1=15.974142383394407\n",
      "SubGD iter. 322/499: loss=5.310579425625379, w0=72.62673267326743, w1=15.97253272267332\n",
      "SubGD iter. 323/499: loss=5.310575724185897, w0=72.62673267326743, w1=15.970923061952233\n",
      "SubGD iter. 324/499: loss=5.310581535209124, w0=72.63366336633673, w1=15.975391761759637\n",
      "SubGD iter. 325/499: loss=5.310623916407671, w0=72.62673267326743, w1=15.9732656619739\n",
      "SubGD iter. 326/499: loss=5.310577409591045, w0=72.62673267326743, w1=15.971656001252812\n",
      "SubGD iter. 327/499: loss=5.310576856229538, w0=72.63366336633673, w1=15.976124701060217\n",
      "SubGD iter. 328/499: loss=5.310626142553512, w0=72.62673267326743, w1=15.973998601274479\n",
      "SubGD iter. 329/499: loss=5.310579094996192, w0=72.62673267326743, w1=15.972388940553392\n",
      "SubGD iter. 330/499: loss=5.31057539355671, w0=72.62673267326743, w1=15.970779279832305\n",
      "SubGD iter. 331/499: loss=5.310582453093599, w0=72.63366336633673, w1=15.97524797963971\n",
      "SubGD iter. 332/499: loss=5.310623479700335, w0=72.62673267326743, w1=15.973121879853972\n",
      "SubGD iter. 333/499: loss=5.310577078961859, w0=72.62673267326743, w1=15.971512219132885\n",
      "SubGD iter. 334/499: loss=5.3105777741140106, w0=72.63366336633673, w1=15.975980918940289\n",
      "SubGD iter. 335/499: loss=5.310625705846178, w0=72.62673267326743, w1=15.973854819154552\n",
      "SubGD iter. 336/499: loss=5.310578764367005, w0=72.62673267326743, w1=15.972245158433465\n",
      "SubGD iter. 337/499: loss=5.3105750629275255, w0=72.62673267326743, w1=15.970635497712378\n",
      "SubGD iter. 338/499: loss=5.3105833709780725, w0=72.63366336633673, w1=15.975104197519782\n",
      "SubGD iter. 339/499: loss=5.310623042993001, w0=72.62673267326743, w1=15.972978097734044\n",
      "SubGD iter. 340/499: loss=5.310576748332672, w0=72.62673267326743, w1=15.971368437012957\n",
      "SubGD iter. 341/499: loss=5.310578691998486, w0=72.63366336633673, w1=15.975837136820362\n",
      "SubGD iter. 342/499: loss=5.310625269138844, w0=72.62673267326743, w1=15.973711037034624\n",
      "SubGD iter. 343/499: loss=5.310578433737818, w0=72.62673267326743, w1=15.972101376313537\n",
      "SubGD iter. 344/499: loss=5.3105747322983365, w0=72.62673267326743, w1=15.97049171559245\n",
      "SubGD iter. 345/499: loss=5.310584288862546, w0=72.63366336633673, w1=15.974960415399854\n",
      "SubGD iter. 346/499: loss=5.3106226062856665, w0=72.62673267326743, w1=15.972834315614117\n",
      "SubGD iter. 347/499: loss=5.310576417703483, w0=72.62673267326743, w1=15.97122465489303\n",
      "SubGD iter. 348/499: loss=5.310579609882957, w0=72.63366336633673, w1=15.975693354700434\n",
      "SubGD iter. 349/499: loss=5.310624832431509, w0=72.62673267326743, w1=15.973567254914697\n",
      "SubGD iter. 350/499: loss=5.3105781031086305, w0=72.62673267326743, w1=15.97195759419361\n",
      "SubGD iter. 351/499: loss=5.310574930903371, w0=72.63366336633673, w1=15.976426294001014\n",
      "SubGD iter. 352/499: loss=5.310627058577351, w0=72.62673267326743, w1=15.974300194215276\n",
      "SubGD iter. 353/499: loss=5.3105797885137775, w0=72.62673267326743, w1=15.97269053349419\n",
      "SubGD iter. 354/499: loss=5.310576087074297, w0=72.62673267326743, w1=15.971080872773102\n",
      "SubGD iter. 355/499: loss=5.310580527767432, w0=72.63366336633673, w1=15.975549572580507\n",
      "SubGD iter. 356/499: loss=5.310624395724175, w0=72.62673267326743, w1=15.973423472794769\n",
      "SubGD iter. 357/499: loss=5.310577772479444, w0=72.62673267326743, w1=15.971813812073682\n",
      "SubGD iter. 358/499: loss=5.3105758487878445, w0=72.63366336633673, w1=15.976282511881086\n",
      "SubGD iter. 359/499: loss=5.310626621870016, w0=72.62673267326743, w1=15.974156412095349\n",
      "SubGD iter. 360/499: loss=5.310579457884592, w0=72.62673267326743, w1=15.972546751374262\n",
      "SubGD iter. 361/499: loss=5.31057575644511, w0=72.62673267326743, w1=15.970937090653175\n",
      "SubGD iter. 362/499: loss=5.310581445651906, w0=72.63366336633673, w1=15.975405790460579\n",
      "SubGD iter. 363/499: loss=5.310623959016839, w0=72.62673267326743, w1=15.973279690674842\n",
      "SubGD iter. 364/499: loss=5.310577441850257, w0=72.62673267326743, w1=15.971670029953755\n",
      "SubGD iter. 365/499: loss=5.310576766672319, w0=72.63366336633673, w1=15.976138729761159\n",
      "SubGD iter. 366/499: loss=5.310626185162682, w0=72.62673267326743, w1=15.974012629975421\n",
      "SubGD iter. 367/499: loss=5.310579127255404, w0=72.62673267326743, w1=15.972402969254334\n",
      "SubGD iter. 368/499: loss=5.310575425815924, w0=72.62673267326743, w1=15.970793308533247\n",
      "SubGD iter. 369/499: loss=5.31058236353638, w0=72.63366336633673, w1=15.975262008340652\n",
      "SubGD iter. 370/499: loss=5.310623522309504, w0=72.62673267326743, w1=15.973135908554914\n",
      "SubGD iter. 371/499: loss=5.31057711122107, w0=72.62673267326743, w1=15.971526247833827\n",
      "SubGD iter. 372/499: loss=5.310577684556793, w0=72.63366336633673, w1=15.975994947641231\n",
      "SubGD iter. 373/499: loss=5.3106257484553465, w0=72.62673267326743, w1=15.973868847855494\n",
      "SubGD iter. 374/499: loss=5.310578796626218, w0=72.62673267326743, w1=15.972259187134407\n",
      "SubGD iter. 375/499: loss=5.310575095186736, w0=72.62673267326743, w1=15.97064952641332\n",
      "SubGD iter. 376/499: loss=5.310583281420854, w0=72.63366336633673, w1=15.975118226220724\n",
      "SubGD iter. 377/499: loss=5.3106230856021694, w0=72.62673267326743, w1=15.972992126434987\n",
      "SubGD iter. 378/499: loss=5.310576780591885, w0=72.62673267326743, w1=15.9713824657139\n",
      "SubGD iter. 379/499: loss=5.310578602441266, w0=72.63366336633673, w1=15.975851165521304\n",
      "SubGD iter. 380/499: loss=5.310625311748012, w0=72.62673267326743, w1=15.973725065735566\n",
      "SubGD iter. 381/499: loss=5.310578465997031, w0=72.62673267326743, w1=15.97211540501448\n",
      "SubGD iter. 382/499: loss=5.31057476455755, w0=72.62673267326743, w1=15.970505744293392\n",
      "SubGD iter. 383/499: loss=5.310584199305326, w0=72.63366336633673, w1=15.974974444100797\n",
      "SubGD iter. 384/499: loss=5.310622648894835, w0=72.62673267326743, w1=15.972848344315059\n",
      "SubGD iter. 385/499: loss=5.310576449962697, w0=72.62673267326743, w1=15.971238683593972\n",
      "SubGD iter. 386/499: loss=5.310579520325739, w0=72.63366336633673, w1=15.975707383401376\n",
      "SubGD iter. 387/499: loss=5.310624875040677, w0=72.62673267326743, w1=15.973581283615639\n",
      "SubGD iter. 388/499: loss=5.3105781353678445, w0=72.62673267326743, w1=15.971971622894552\n",
      "SubGD iter. 389/499: loss=5.310574841346153, w0=72.63366336633673, w1=15.976440322701956\n",
      "SubGD iter. 390/499: loss=5.31062710118652, w0=72.62673267326743, w1=15.974314222916218\n",
      "SubGD iter. 391/499: loss=5.3105798207729915, w0=72.62673267326743, w1=15.972704562195132\n",
      "SubGD iter. 392/499: loss=5.3105761193335095, w0=72.62673267326743, w1=15.971094901474045\n",
      "SubGD iter. 393/499: loss=5.310580438210215, w0=72.63366336633673, w1=15.975563601281449\n",
      "SubGD iter. 394/499: loss=5.310624438333342, w0=72.62673267326743, w1=15.973437501495711\n",
      "SubGD iter. 395/499: loss=5.3105778047386565, w0=72.62673267326743, w1=15.971827840774624\n",
      "SubGD iter. 396/499: loss=5.310575759230627, w0=72.63366336633673, w1=15.976296540582029\n",
      "SubGD iter. 397/499: loss=5.3106266644791855, w0=72.62673267326743, w1=15.974170440796291\n",
      "SubGD iter. 398/499: loss=5.3105794901438035, w0=72.62673267326743, w1=15.972560780075204\n",
      "SubGD iter. 399/499: loss=5.310575788704323, w0=72.62673267326743, w1=15.970951119354117\n",
      "SubGD iter. 400/499: loss=5.310581356094687, w0=72.63366336633673, w1=15.975419819161521\n",
      "SubGD iter. 401/499: loss=5.310624001626008, w0=72.62673267326743, w1=15.973293719375784\n",
      "SubGD iter. 402/499: loss=5.31057747410947, w0=72.62673267326743, w1=15.971684058654697\n",
      "SubGD iter. 403/499: loss=5.310576677115099, w0=72.63366336633673, w1=15.976152758462101\n",
      "SubGD iter. 404/499: loss=5.31062622777185, w0=72.62673267326743, w1=15.974026658676364\n",
      "SubGD iter. 405/499: loss=5.310579159514617, w0=72.62673267326743, w1=15.972416997955277\n",
      "SubGD iter. 406/499: loss=5.310575458075137, w0=72.62673267326743, w1=15.97080733723419\n",
      "SubGD iter. 407/499: loss=5.310582273979161, w0=72.63366336633673, w1=15.975276037041594\n",
      "SubGD iter. 408/499: loss=5.310623564918673, w0=72.62673267326743, w1=15.973149937255856\n",
      "SubGD iter. 409/499: loss=5.310577143480284, w0=72.62673267326743, w1=15.97154027653477\n",
      "SubGD iter. 410/499: loss=5.310577594999573, w0=72.63366336633673, w1=15.976008976342174\n",
      "SubGD iter. 411/499: loss=5.310625791064515, w0=72.62673267326743, w1=15.973882876556436\n",
      "SubGD iter. 412/499: loss=5.31057882888543, w0=72.62673267326743, w1=15.972273215835349\n",
      "SubGD iter. 413/499: loss=5.310575127445949, w0=72.62673267326743, w1=15.970663555114262\n",
      "SubGD iter. 414/499: loss=5.3105831918636355, w0=72.63366336633673, w1=15.975132254921666\n",
      "SubGD iter. 415/499: loss=5.310623128211338, w0=72.62673267326743, w1=15.973006155135929\n",
      "SubGD iter. 416/499: loss=5.310576812851096, w0=72.62673267326743, w1=15.971396494414842\n",
      "SubGD iter. 417/499: loss=5.310578512884048, w0=72.63366336633673, w1=15.975865194222246\n",
      "SubGD iter. 418/499: loss=5.31062535435718, w0=72.62673267326743, w1=15.973739094436509\n",
      "SubGD iter. 419/499: loss=5.310578498256244, w0=72.62673267326743, w1=15.972129433715422\n",
      "SubGD iter. 420/499: loss=5.310574796816762, w0=72.62673267326743, w1=15.970519772994335\n",
      "SubGD iter. 421/499: loss=5.31058410974811, w0=72.63366336633673, w1=15.974988472801739\n",
      "SubGD iter. 422/499: loss=5.310622691504003, w0=72.62673267326743, w1=15.972862373016001\n",
      "SubGD iter. 423/499: loss=5.310576482221909, w0=72.62673267326743, w1=15.971252712294914\n",
      "SubGD iter. 424/499: loss=5.310579430768521, w0=72.63366336633673, w1=15.975721412102319\n",
      "SubGD iter. 425/499: loss=5.310624917649847, w0=72.62673267326743, w1=15.973595312316581\n",
      "SubGD iter. 426/499: loss=5.310578167627056, w0=72.62673267326743, w1=15.971985651595494\n",
      "SubGD iter. 427/499: loss=5.310574751788934, w0=72.63366336633673, w1=15.976454351402898\n",
      "SubGD iter. 428/499: loss=5.310627143795689, w0=72.62673267326743, w1=15.97432825161716\n",
      "SubGD iter. 429/499: loss=5.310579853032204, w0=72.62673267326743, w1=15.972718590896074\n",
      "SubGD iter. 430/499: loss=5.310576151592722, w0=72.62673267326743, w1=15.971108930174987\n",
      "SubGD iter. 431/499: loss=5.310580348652994, w0=72.63366336633673, w1=15.975577629982391\n",
      "SubGD iter. 432/499: loss=5.310624480942511, w0=72.62673267326743, w1=15.973451530196654\n",
      "SubGD iter. 433/499: loss=5.31057783699787, w0=72.62673267326743, w1=15.971841869475567\n",
      "SubGD iter. 434/499: loss=5.310575669673408, w0=72.63366336633673, w1=15.97631056928297\n",
      "SubGD iter. 435/499: loss=5.310626707088354, w0=72.62673267326743, w1=15.974184469497233\n",
      "SubGD iter. 436/499: loss=5.3105795224030174, w0=72.62673267326743, w1=15.972574808776146\n",
      "SubGD iter. 437/499: loss=5.310575820963536, w0=72.62673267326743, w1=15.97096514805506\n",
      "SubGD iter. 438/499: loss=5.3105812665374685, w0=72.63366336633673, w1=15.975433847862464\n",
      "SubGD iter. 439/499: loss=5.310624044235177, w0=72.62673267326743, w1=15.973307748076726\n",
      "SubGD iter. 440/499: loss=5.310577506368683, w0=72.62673267326743, w1=15.97169808735564\n",
      "SubGD iter. 441/499: loss=5.310576587557881, w0=72.63366336633673, w1=15.976166787163043\n",
      "SubGD iter. 442/499: loss=5.310626270381019, w0=72.62673267326743, w1=15.974040687377306\n",
      "SubGD iter. 443/499: loss=5.31057919177383, w0=72.62673267326743, w1=15.972431026656219\n",
      "SubGD iter. 444/499: loss=5.310575490334348, w0=72.62673267326743, w1=15.970821365935132\n",
      "SubGD iter. 445/499: loss=5.310582184421943, w0=72.63366336633673, w1=15.975290065742536\n",
      "SubGD iter. 446/499: loss=5.310623607527843, w0=72.62673267326743, w1=15.973163965956799\n",
      "SubGD iter. 447/499: loss=5.310577175739496, w0=72.62673267326743, w1=15.971554305235712\n",
      "SubGD iter. 448/499: loss=5.310577505442355, w0=72.63366336633673, w1=15.976023005043116\n",
      "SubGD iter. 449/499: loss=5.310625833673684, w0=72.62673267326743, w1=15.973896905257378\n",
      "SubGD iter. 450/499: loss=5.310578861144643, w0=72.62673267326743, w1=15.972287244536291\n",
      "SubGD iter. 451/499: loss=5.310575159705161, w0=72.62673267326743, w1=15.970677583815204\n",
      "SubGD iter. 452/499: loss=5.310583102306416, w0=72.63366336633673, w1=15.975146283622609\n",
      "SubGD iter. 453/499: loss=5.310623170820506, w0=72.62673267326743, w1=15.973020183836871\n",
      "SubGD iter. 454/499: loss=5.310576845110308, w0=72.62673267326743, w1=15.971410523115784\n",
      "SubGD iter. 455/499: loss=5.310578423326828, w0=72.63366336633673, w1=15.975879222923188\n",
      "SubGD iter. 456/499: loss=5.3106253969663495, w0=72.62673267326743, w1=15.97375312313745\n",
      "SubGD iter. 457/499: loss=5.310578530515456, w0=72.62673267326743, w1=15.972143462416364\n",
      "SubGD iter. 458/499: loss=5.310574829075976, w0=72.62673267326743, w1=15.970533801695277\n",
      "SubGD iter. 459/499: loss=5.31058402019089, w0=72.63366336633673, w1=15.975002501502681\n",
      "SubGD iter. 460/499: loss=5.3106227341131715, w0=72.62673267326743, w1=15.972876401716944\n",
      "SubGD iter. 461/499: loss=5.310576514481123, w0=72.62673267326743, w1=15.971266740995857\n",
      "SubGD iter. 462/499: loss=5.3105793412113025, w0=72.63366336633673, w1=15.97573544080326\n",
      "SubGD iter. 463/499: loss=5.310624960259015, w0=72.62673267326743, w1=15.973609341017523\n",
      "SubGD iter. 464/499: loss=5.310578199886269, w0=72.62673267326743, w1=15.971999680296436\n",
      "SubGD iter. 465/499: loss=5.310574662231713, w0=72.63366336633673, w1=15.97646838010384\n",
      "SubGD iter. 466/499: loss=5.310627186404858, w0=72.62673267326743, w1=15.974342280318103\n",
      "SubGD iter. 467/499: loss=5.310579885291418, w0=72.62673267326743, w1=15.972732619597016\n",
      "SubGD iter. 468/499: loss=5.310576183851936, w0=72.62673267326743, w1=15.97112295887593\n",
      "SubGD iter. 469/499: loss=5.310580259095775, w0=72.63366336633673, w1=15.975591658683333\n",
      "SubGD iter. 470/499: loss=5.31062452355168, w0=72.62673267326743, w1=15.973465558897596\n",
      "SubGD iter. 471/499: loss=5.310577869257083, w0=72.62673267326743, w1=15.971855898176509\n",
      "SubGD iter. 472/499: loss=5.310575580116187, w0=72.63366336633673, w1=15.976324597983913\n",
      "SubGD iter. 473/499: loss=5.310626749697522, w0=72.62673267326743, w1=15.974198498198175\n",
      "SubGD iter. 474/499: loss=5.3105795546622305, w0=72.62673267326743, w1=15.972588837477089\n",
      "SubGD iter. 475/499: loss=5.3105758532227485, w0=72.62673267326743, w1=15.970979176756002\n",
      "SubGD iter. 476/499: loss=5.31058117698025, w0=72.63366336633673, w1=15.975447876563406\n",
      "SubGD iter. 477/499: loss=5.310624086844345, w0=72.62673267326743, w1=15.973321776777668\n",
      "SubGD iter. 478/499: loss=5.3105775386278955, w0=72.62673267326743, w1=15.971712116056581\n",
      "SubGD iter. 479/499: loss=5.3105764980006605, w0=72.63366336633673, w1=15.976180815863986\n",
      "SubGD iter. 480/499: loss=5.310626312990188, w0=72.62673267326743, w1=15.974054716078248\n",
      "SubGD iter. 481/499: loss=5.3105792240330425, w0=72.62673267326743, w1=15.972445055357161\n",
      "SubGD iter. 482/499: loss=5.3105755225935605, w0=72.62673267326743, w1=15.970835394636074\n",
      "SubGD iter. 483/499: loss=5.310582094864723, w0=72.63366336633673, w1=15.975304094443478\n",
      "SubGD iter. 484/499: loss=5.31062365013701, w0=72.62673267326743, w1=15.97317799465774\n",
      "SubGD iter. 485/499: loss=5.3105772079987075, w0=72.62673267326743, w1=15.971568333936654\n",
      "SubGD iter. 486/499: loss=5.3105774158851355, w0=72.63366336633673, w1=15.976037033744058\n",
      "SubGD iter. 487/499: loss=5.310625876282852, w0=72.62673267326743, w1=15.97391093395832\n",
      "SubGD iter. 488/499: loss=5.310578893403856, w0=72.62673267326743, w1=15.972301273237234\n",
      "SubGD iter. 489/499: loss=5.310575191964374, w0=72.62673267326743, w1=15.970691612516147\n",
      "SubGD iter. 490/499: loss=5.3105830127491975, w0=72.63366336633673, w1=15.97516031232355\n",
      "SubGD iter. 491/499: loss=5.310623213429675, w0=72.62673267326743, w1=15.973034212537813\n",
      "SubGD iter. 492/499: loss=5.310576877369521, w0=72.62673267326743, w1=15.971424551816726\n",
      "SubGD iter. 493/499: loss=5.31057833376961, w0=72.63366336633673, w1=15.97589325162413\n",
      "SubGD iter. 494/499: loss=5.310625439575518, w0=72.62673267326743, w1=15.973767151838393\n",
      "SubGD iter. 495/499: loss=5.310578562774669, w0=72.62673267326743, w1=15.972157491117306\n",
      "SubGD iter. 496/499: loss=5.310574861335188, w0=72.62673267326743, w1=15.97054783039622\n",
      "SubGD iter. 497/499: loss=5.310583930633671, w0=72.63366336633673, w1=15.975016530203623\n",
      "SubGD iter. 498/499: loss=5.310622776722341, w0=72.62673267326743, w1=15.972890430417886\n",
      "SubGD iter. 499/499: loss=5.310576546740335, w0=72.62673267326743, w1=15.971280769696799\n",
      "SubGD: execution time=0.053 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5685065b55ba45fe8bc6b582038b9b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        batch_indices = np.random.choice(tx.shape[0], batch_size)\n",
    "        y_batch = y[batch_indices]\n",
    "        tx_batch = tx[batch_indices]\n",
    "        subgradient = compute_subgradient_mae(y_batch, tx_batch, w)\n",
    "        w = w - gamma * subgradient\n",
    "        loss = compute_loss_mae(y, tx, w)\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=73.36780585492637, w0=0.7, w1=0.046720324846674724\n",
      "SubSGD iter. 1/499: loss=72.66780585492639, w0=1.4, w1=0.14184124386196387\n",
      "SubSGD iter. 2/499: loss=71.96780585492637, w0=2.0999999999999996, w1=-0.0041214426034715534\n",
      "SubSGD iter. 3/499: loss=71.26780585492638, w0=2.8, w1=-0.19362894901735442\n",
      "SubSGD iter. 4/499: loss=70.56780585492638, w0=3.5, w1=-0.3643764363709542\n",
      "SubSGD iter. 5/499: loss=69.86780585492637, w0=4.2, w1=-0.5378685196420437\n",
      "SubSGD iter. 6/499: loss=69.16780585492639, w0=4.9, w1=-0.9047632166675486\n",
      "SubSGD iter. 7/499: loss=68.46780585492638, w0=5.6000000000000005, w1=-0.8714218539328268\n",
      "SubSGD iter. 8/499: loss=67.7678058549264, w0=6.300000000000001, w1=-0.4607970871309684\n",
      "SubSGD iter. 9/499: loss=67.06780585492638, w0=7.000000000000001, w1=-0.6041848726574598\n",
      "SubSGD iter. 10/499: loss=66.36780585492637, w0=7.700000000000001, w1=-0.621816008109203\n",
      "SubSGD iter. 11/499: loss=65.66780585492637, w0=8.4, w1=-0.5747255607644977\n",
      "SubSGD iter. 12/499: loss=64.96780585492637, w0=9.1, w1=-0.23208100712944357\n",
      "SubSGD iter. 13/499: loss=64.26780585492638, w0=9.799999999999999, w1=-0.24562547253802347\n",
      "SubSGD iter. 14/499: loss=63.56780585492636, w0=10.499999999999998, w1=0.04552120706997098\n",
      "SubSGD iter. 15/499: loss=62.867805854926374, w0=11.199999999999998, w1=0.29645635143399335\n",
      "SubSGD iter. 16/499: loss=62.16780585492638, w0=11.899999999999997, w1=0.26369961728093355\n",
      "SubSGD iter. 17/499: loss=61.46780585492638, w0=12.599999999999996, w1=0.08821035758454845\n",
      "SubSGD iter. 18/499: loss=60.76780585492638, w0=13.299999999999995, w1=-0.06714432566973474\n",
      "SubSGD iter. 19/499: loss=60.06780585492639, w0=13.999999999999995, w1=0.18491115955618712\n",
      "SubSGD iter. 20/499: loss=59.367805854926374, w0=14.699999999999994, w1=0.17817069113117032\n",
      "SubSGD iter. 21/499: loss=58.667805854926385, w0=15.399999999999993, w1=0.46178380879584713\n",
      "SubSGD iter. 22/499: loss=57.96780585492638, w0=16.099999999999994, w1=0.3103377481560615\n",
      "SubSGD iter. 23/499: loss=57.26780585492638, w0=16.799999999999994, w1=0.31209216105438115\n",
      "SubSGD iter. 24/499: loss=56.567805854926384, w0=17.499999999999993, w1=0.38854117819808415\n",
      "SubSGD iter. 25/499: loss=55.86780585492639, w0=18.199999999999992, w1=0.10819544672498993\n",
      "SubSGD iter. 26/499: loss=55.167805854926385, w0=18.89999999999999, w1=0.4261397955343606\n",
      "SubSGD iter. 27/499: loss=54.46780585492638, w0=19.59999999999999, w1=0.3401889760863178\n",
      "SubSGD iter. 28/499: loss=53.767805854926394, w0=20.29999999999999, w1=0.2032453289158468\n",
      "SubSGD iter. 29/499: loss=53.067805854926384, w0=20.99999999999999, w1=0.2624016420127462\n",
      "SubSGD iter. 30/499: loss=52.367805854926395, w0=21.69999999999999, w1=0.6829567690664219\n",
      "SubSGD iter. 31/499: loss=51.667805854926385, w0=22.399999999999988, w1=0.6320970272803598\n",
      "SubSGD iter. 32/499: loss=50.96780585492639, w0=23.099999999999987, w1=0.543048300455701\n",
      "SubSGD iter. 33/499: loss=50.267805854926394, w0=23.799999999999986, w1=0.5728395104807655\n",
      "SubSGD iter. 34/499: loss=49.567805854926384, w0=24.499999999999986, w1=0.5133521525010507\n",
      "SubSGD iter. 35/499: loss=48.867805854926395, w0=25.199999999999985, w1=0.794080496341566\n",
      "SubSGD iter. 36/499: loss=48.167805854926385, w0=25.899999999999984, w1=0.6877404091534199\n",
      "SubSGD iter. 37/499: loss=47.4678058549264, w0=26.599999999999984, w1=0.428859630679183\n",
      "SubSGD iter. 38/499: loss=46.767805854926394, w0=27.299999999999983, w1=0.5931066749352546\n",
      "SubSGD iter. 39/499: loss=46.06780585492639, w0=27.999999999999982, w1=1.0174046861541626\n",
      "SubSGD iter. 40/499: loss=45.367805854926395, w0=28.69999999999998, w1=1.316895405707337\n",
      "SubSGD iter. 41/499: loss=44.66780585492641, w0=29.39999999999998, w1=1.342635872616678\n",
      "SubSGD iter. 42/499: loss=43.9678058549264, w0=30.09999999999998, w1=1.345051742957426\n",
      "SubSGD iter. 43/499: loss=43.2678058549264, w0=30.79999999999998, w1=1.710560587953915\n",
      "SubSGD iter. 44/499: loss=42.567805854926405, w0=31.49999999999998, w1=1.9240397972793177\n",
      "SubSGD iter. 45/499: loss=41.867805854926395, w0=32.19999999999998, w1=1.934069699027289\n",
      "SubSGD iter. 46/499: loss=41.1678058549264, w0=32.899999999999984, w1=1.6751514712827986\n",
      "SubSGD iter. 47/499: loss=40.46780585492639, w0=33.59999999999999, w1=1.6319319536340275\n",
      "SubSGD iter. 48/499: loss=39.76780585492639, w0=34.29999999999999, w1=1.8469028259083682\n",
      "SubSGD iter. 49/499: loss=39.067805854926384, w0=34.99999999999999, w1=1.4643429501254661\n",
      "SubSGD iter. 50/499: loss=38.36780585492639, w0=35.699999999999996, w1=1.6521513844921905\n",
      "SubSGD iter. 51/499: loss=37.66780585492638, w0=36.4, w1=1.874192177915108\n",
      "SubSGD iter. 52/499: loss=36.967805854926375, w0=37.1, w1=2.1567621883014927\n",
      "SubSGD iter. 53/499: loss=36.267805854926365, w0=37.800000000000004, w1=1.7308686066146886\n",
      "SubSGD iter. 54/499: loss=35.56780585492636, w0=38.50000000000001, w1=1.8156221901391447\n",
      "SubSGD iter. 55/499: loss=34.86780585492636, w0=39.20000000000001, w1=1.6581138479525774\n",
      "SubSGD iter. 56/499: loss=34.16780585492636, w0=39.90000000000001, w1=1.767332303242113\n",
      "SubSGD iter. 57/499: loss=33.46780585492636, w0=40.600000000000016, w1=1.820047783789024\n",
      "SubSGD iter. 58/499: loss=32.76780585492636, w0=41.30000000000002, w1=1.9954476691382377\n",
      "SubSGD iter. 59/499: loss=32.067805854926355, w0=42.00000000000002, w1=1.8668213746651527\n",
      "SubSGD iter. 60/499: loss=31.367805854926353, w0=42.700000000000024, w1=1.9160999131468588\n",
      "SubSGD iter. 61/499: loss=30.66780585492635, w0=43.40000000000003, w1=1.9276270087922827\n",
      "SubSGD iter. 62/499: loss=29.967805854926343, w0=44.10000000000003, w1=2.0399526582989216\n",
      "SubSGD iter. 63/499: loss=29.267805854926348, w0=44.80000000000003, w1=1.882616546435977\n",
      "SubSGD iter. 64/499: loss=28.567805854926345, w0=45.500000000000036, w1=1.6512699139334468\n",
      "SubSGD iter. 65/499: loss=27.867805854926342, w0=46.20000000000004, w1=1.3338718536797773\n",
      "SubSGD iter. 66/499: loss=27.167805854926332, w0=46.90000000000004, w1=1.6969636703394566\n",
      "SubSGD iter. 67/499: loss=26.467805854926336, w0=47.600000000000044, w1=2.036865259128255\n",
      "SubSGD iter. 68/499: loss=25.767805854926326, w0=48.30000000000005, w1=2.3912962639416118\n",
      "SubSGD iter. 69/499: loss=25.067805854926327, w0=49.00000000000005, w1=3.0649762497220556\n",
      "SubSGD iter. 70/499: loss=24.367805854926324, w0=49.70000000000005, w1=3.2236495599924244\n",
      "SubSGD iter. 71/499: loss=23.66780585492632, w0=50.400000000000055, w1=3.4875260025914994\n",
      "SubSGD iter. 72/499: loss=22.96780585492632, w0=51.10000000000006, w1=3.320216746015773\n",
      "SubSGD iter. 73/499: loss=22.267813599469488, w0=51.80000000000006, w1=3.4381574569495665\n",
      "SubSGD iter. 74/499: loss=21.577395141935014, w0=52.500000000000064, w1=3.5753163672616424\n",
      "SubSGD iter. 75/499: loss=20.91152735751002, w0=53.20000000000007, w1=3.31183707992326\n",
      "SubSGD iter. 76/499: loss=20.228013037556295, w0=53.90000000000007, w1=3.5246946971083157\n",
      "SubSGD iter. 77/499: loss=19.552141489637798, w0=54.60000000000007, w1=3.592779786786107\n",
      "SubSGD iter. 78/499: loss=18.88788649280601, w0=55.300000000000075, w1=3.613374202410263\n",
      "SubSGD iter. 79/499: loss=18.241535267591125, w0=56.00000000000008, w1=3.670332759605693\n",
      "SubSGD iter. 80/499: loss=17.81064369257048, w0=56.42000000000008, w1=4.056735650704567\n",
      "SubSGD iter. 81/499: loss=17.290758848996067, w0=56.98000000000008, w1=4.1783644658561805\n",
      "SubSGD iter. 82/499: loss=16.758750147332385, w0=57.680000000000085, w1=3.857647343263258\n",
      "SubSGD iter. 83/499: loss=16.253481947532443, w0=58.24000000000009, w1=4.107371953899304\n",
      "SubSGD iter. 84/499: loss=15.675123013647726, w0=58.94000000000009, w1=4.271365875827533\n",
      "SubSGD iter. 85/499: loss=15.213009029524699, w0=59.64000000000009, w1=4.115077322537316\n",
      "SubSGD iter. 86/499: loss=14.825331525552974, w0=60.060000000000095, w1=4.424715267454148\n",
      "SubSGD iter. 87/499: loss=14.279508540022976, w0=60.7600000000001, w1=4.645020830949129\n",
      "SubSGD iter. 88/499: loss=13.952149251931013, w0=61.1800000000001, w1=4.820277955364553\n",
      "SubSGD iter. 89/499: loss=13.50450131730985, w0=61.8800000000001, w1=4.90112018004411\n",
      "SubSGD iter. 90/499: loss=13.173800006555217, w0=62.0200000000001, w1=5.535583050369601\n",
      "SubSGD iter. 91/499: loss=12.702649664058384, w0=62.580000000000105, w1=5.911596220890418\n",
      "SubSGD iter. 92/499: loss=12.304463205078143, w0=63.00000000000011, w1=6.319560424643699\n",
      "SubSGD iter. 93/499: loss=11.941460221917675, w0=63.56000000000011, w1=6.470986903530789\n",
      "SubSGD iter. 94/499: loss=11.494566561890283, w0=64.1200000000001, w1=6.8352400978889545\n",
      "SubSGD iter. 95/499: loss=11.17787142826716, w0=64.4000000000001, w1=7.240991992532003\n",
      "SubSGD iter. 96/499: loss=10.904454684945051, w0=64.5400000000001, w1=7.715812259069564\n",
      "SubSGD iter. 97/499: loss=10.748273678247193, w0=64.5400000000001, w1=8.111724339674707\n",
      "SubSGD iter. 98/499: loss=10.440600598865682, w0=64.8200000000001, w1=8.513758339108874\n",
      "SubSGD iter. 99/499: loss=10.045369177533031, w0=65.52000000000011, w1=8.573012628319972\n",
      "SubSGD iter. 100/499: loss=9.868540496590784, w0=65.66000000000011, w1=8.835397243001664\n",
      "SubSGD iter. 101/499: loss=9.516996035092484, w0=65.94000000000011, w1=9.378360453346886\n",
      "SubSGD iter. 102/499: loss=9.244889837534977, w0=66.36000000000011, w1=9.518827040321545\n",
      "SubSGD iter. 103/499: loss=8.961242899132726, w0=66.78000000000011, w1=9.699883678089707\n",
      "SubSGD iter. 104/499: loss=8.82791419112997, w0=66.92000000000012, w1=9.872436401101918\n",
      "SubSGD iter. 105/499: loss=8.522492886262446, w0=67.34000000000012, w1=10.151564337039307\n",
      "SubSGD iter. 106/499: loss=8.430179994506847, w0=67.34000000000012, w1=10.395674818927723\n",
      "SubSGD iter. 107/499: loss=8.240293598562516, w0=67.48000000000012, w1=10.736110036767045\n",
      "SubSGD iter. 108/499: loss=7.937086270171431, w0=67.76000000000012, w1=11.23480233385091\n",
      "SubSGD iter. 109/499: loss=7.849368849543923, w0=68.04000000000012, w1=11.130187557789554\n",
      "SubSGD iter. 110/499: loss=7.700241190349268, w0=68.32000000000012, w1=11.225726040184583\n",
      "SubSGD iter. 111/499: loss=7.450566979834953, w0=68.74000000000012, w1=11.449169579426435\n",
      "SubSGD iter. 112/499: loss=7.11784685799865, w0=69.16000000000012, w1=11.915973873234046\n",
      "SubSGD iter. 113/499: loss=6.958149487233069, w0=69.30000000000013, w1=12.230683114629093\n",
      "SubSGD iter. 114/499: loss=6.818724949554296, w0=69.44000000000013, w1=12.494377461457137\n",
      "SubSGD iter. 115/499: loss=6.579498141244733, w0=69.72000000000013, w1=12.912243237715728\n",
      "SubSGD iter. 116/499: loss=6.531427649294402, w0=69.58000000000013, w1=13.231925689355341\n",
      "SubSGD iter. 117/499: loss=6.302028506056837, w0=69.86000000000013, w1=13.645636872226747\n",
      "SubSGD iter. 118/499: loss=6.168919464859905, w0=70.28000000000013, w1=13.590302159587079\n",
      "SubSGD iter. 119/499: loss=6.091138606116757, w0=70.42000000000013, w1=13.695656091797911\n",
      "SubSGD iter. 120/499: loss=6.029652421364014, w0=70.42000000000013, w1=13.91021133695471\n",
      "SubSGD iter. 121/499: loss=6.074993798383566, w0=70.56000000000013, w1=13.609091110754447\n",
      "SubSGD iter. 122/499: loss=5.8989460589733556, w0=70.98000000000013, w1=13.792732142761938\n",
      "SubSGD iter. 123/499: loss=5.865599519742727, w0=70.84000000000013, w1=14.027964767733353\n",
      "SubSGD iter. 124/499: loss=5.887112179816523, w0=70.56000000000013, w1=14.272184135504387\n",
      "SubSGD iter. 125/499: loss=5.772606751790219, w0=70.98000000000013, w1=14.214792971566652\n",
      "SubSGD iter. 126/499: loss=5.652518168014829, w0=70.98000000000013, w1=14.732150434627588\n",
      "SubSGD iter. 127/499: loss=5.490967340528413, w0=71.40000000000013, w1=15.106215829319037\n",
      "SubSGD iter. 128/499: loss=5.502883214659265, w0=71.26000000000013, w1=15.27481686305095\n",
      "SubSGD iter. 129/499: loss=5.466539487992898, w0=71.40000000000013, w1=15.342984304952212\n",
      "SubSGD iter. 130/499: loss=5.464312287482467, w0=71.40000000000013, w1=15.367847238898257\n",
      "SubSGD iter. 131/499: loss=5.4232901238179325, w0=71.54000000000013, w1=15.546022345616974\n",
      "SubSGD iter. 132/499: loss=5.437108296304788, w0=71.54000000000013, w1=15.382164135798517\n",
      "SubSGD iter. 133/499: loss=5.455973596810367, w0=71.40000000000013, w1=15.472253635744496\n",
      "SubSGD iter. 134/499: loss=5.40519964237506, w0=71.96000000000014, w1=15.111012798541026\n",
      "SubSGD iter. 135/499: loss=5.357900628508221, w0=72.24000000000014, w1=15.294393897041758\n",
      "SubSGD iter. 136/499: loss=5.338836952306972, w0=72.24000000000014, w1=15.545934533212147\n",
      "SubSGD iter. 137/499: loss=5.329323726331679, w0=72.52000000000014, w1=15.44421525393599\n",
      "SubSGD iter. 138/499: loss=5.311473506444998, w0=72.66000000000014, w1=15.807576118929697\n",
      "SubSGD iter. 139/499: loss=5.312927100595794, w0=72.80000000000014, w1=15.95217392882124\n",
      "SubSGD iter. 140/499: loss=5.321652057606658, w0=72.80000000000014, w1=15.619499671125864\n",
      "SubSGD iter. 141/499: loss=5.319611363207855, w0=72.66000000000014, w1=15.586296453628105\n",
      "SubSGD iter. 142/499: loss=5.322416371960428, w0=72.38000000000014, w1=15.758466066600514\n",
      "SubSGD iter. 143/499: loss=5.313634208402117, w0=72.52000000000014, w1=15.918323894914923\n",
      "SubSGD iter. 144/499: loss=5.319008877462006, w0=72.38000000000014, w1=16.035588587013812\n",
      "SubSGD iter. 145/499: loss=5.318961712855287, w0=72.38000000000014, w1=16.042825408243885\n",
      "SubSGD iter. 146/499: loss=5.319169514564523, w0=72.38000000000014, w1=16.010940825171623\n",
      "SubSGD iter. 147/499: loss=5.315273614413744, w0=72.52000000000014, w1=15.81118460357158\n",
      "SubSGD iter. 148/499: loss=5.32688896107093, w0=72.38000000000014, w1=15.612789063721227\n",
      "SubSGD iter. 149/499: loss=5.323624115015197, w0=72.66000000000014, w1=15.513997886104596\n",
      "SubSGD iter. 150/499: loss=5.38423907277799, w0=72.66000000000014, w1=14.828628720580873\n",
      "SubSGD iter. 151/499: loss=5.374294579866231, w0=72.94000000000014, w1=14.875852090780322\n",
      "SubSGD iter. 152/499: loss=5.3509827300533015, w0=72.66000000000014, w1=15.132461872301379\n",
      "SubSGD iter. 153/499: loss=5.3466239410065475, w0=72.38000000000014, w1=15.30901013580363\n",
      "SubSGD iter. 154/499: loss=5.4014589351309255, w0=72.38000000000014, w1=14.840545065403406\n",
      "SubSGD iter. 155/499: loss=5.398509644243471, w0=72.38000000000014, w1=14.861572269270303\n",
      "SubSGD iter. 156/499: loss=5.400631174350531, w0=72.80000000000014, w1=14.670571212713426\n",
      "SubSGD iter. 157/499: loss=5.436674234839372, w0=72.52000000000014, w1=14.523797726587786\n",
      "SubSGD iter. 158/499: loss=5.352676472035442, w0=72.66000000000014, w1=15.114998070308731\n",
      "SubSGD iter. 159/499: loss=5.346630600441588, w0=72.94000000000014, w1=15.238526466512273\n",
      "SubSGD iter. 160/499: loss=5.347057226900971, w0=73.22000000000014, w1=15.44317900163753\n",
      "SubSGD iter. 161/499: loss=5.33818509894287, w0=73.22000000000014, w1=15.809929640320254\n",
      "SubSGD iter. 162/499: loss=5.32522570234934, w0=73.08000000000014, w1=16.072519624985095\n",
      "SubSGD iter. 163/499: loss=5.324740589861065, w0=72.94000000000014, w1=16.314127512890636\n",
      "SubSGD iter. 164/499: loss=5.329666574923779, w0=72.52000000000014, w1=16.510878293568148\n",
      "SubSGD iter. 165/499: loss=5.325631236445166, w0=72.52000000000014, w1=16.451072996485944\n",
      "SubSGD iter. 166/499: loss=5.337268041860924, w0=72.24000000000014, w1=16.410004988978635\n",
      "SubSGD iter. 167/499: loss=5.313500655208917, w0=72.52000000000014, w1=16.097631295337305\n",
      "SubSGD iter. 168/499: loss=5.319909636745163, w0=72.38000000000014, w1=16.19158771063575\n",
      "SubSGD iter. 169/499: loss=5.338465756461478, w0=72.10000000000014, w1=16.068030416517455\n",
      "SubSGD iter. 170/499: loss=5.336979802267556, w0=72.24000000000014, w1=16.4035085010454\n",
      "SubSGD iter. 171/499: loss=5.344931355891803, w0=72.24000000000014, w1=16.546641677740574\n",
      "SubSGD iter. 172/499: loss=5.333214750721416, w0=72.24000000000014, w1=16.31864988862576\n",
      "SubSGD iter. 173/499: loss=5.350960834409623, w0=72.10000000000014, w1=16.452781473418305\n",
      "SubSGD iter. 174/499: loss=5.348453824059676, w0=72.10000000000014, w1=16.400835094896088\n",
      "SubSGD iter. 175/499: loss=5.3456275461264555, w0=72.10000000000014, w1=16.340986881534693\n",
      "SubSGD iter. 176/499: loss=5.345350072760358, w0=72.10000000000014, w1=15.681962306476859\n",
      "SubSGD iter. 177/499: loss=5.3692013193436825, w0=71.82000000000014, w1=16.003205326335785\n",
      "SubSGD iter. 178/499: loss=5.355523525016941, w0=71.96000000000014, w1=16.151235216836632\n",
      "SubSGD iter. 179/499: loss=5.3743332505498405, w0=71.82000000000014, w1=16.18396142944537\n",
      "SubSGD iter. 180/499: loss=5.3617219015437785, w0=71.96000000000014, w1=16.374457140354927\n",
      "SubSGD iter. 181/499: loss=5.3693812302252, w0=71.96000000000014, w1=16.52247920551278\n",
      "SubSGD iter. 182/499: loss=5.394932001207198, w0=71.68000000000013, w1=16.22565864454037\n",
      "SubSGD iter. 183/499: loss=5.334236150228858, w0=72.24000000000014, w1=15.685594282137602\n",
      "SubSGD iter. 184/499: loss=5.328514168057213, w0=72.24000000000014, w1=15.92561958087382\n",
      "SubSGD iter. 185/499: loss=5.313139130069122, w0=72.52000000000014, w1=16.00732003791706\n",
      "SubSGD iter. 186/499: loss=5.323815852686363, w0=72.38000000000014, w1=15.707763220463546\n",
      "SubSGD iter. 187/499: loss=5.315164562245311, w0=72.66000000000014, w1=15.66766275871621\n",
      "SubSGD iter. 188/499: loss=5.312769312319078, w0=72.80000000000014, w1=15.845484737015619\n",
      "SubSGD iter. 189/499: loss=5.31339204892576, w0=72.80000000000014, w1=16.061958141659364\n",
      "SubSGD iter. 190/499: loss=5.32031833188728, w0=72.94000000000014, w1=15.80377645353857\n",
      "SubSGD iter. 191/499: loss=5.351416275754748, w0=73.36000000000014, w1=15.671292310551665\n",
      "SubSGD iter. 192/499: loss=5.363164061139426, w0=73.50000000000014, w1=15.736329455093529\n",
      "SubSGD iter. 193/499: loss=5.34398474236912, w0=73.08000000000014, w1=15.363033201698563\n",
      "SubSGD iter. 194/499: loss=5.330060579131135, w0=72.94000000000014, w1=15.54737360187744\n",
      "SubSGD iter. 195/499: loss=5.315477156883119, w0=72.80000000000014, w1=15.75097480020411\n",
      "SubSGD iter. 196/499: loss=5.327512570893578, w0=72.24000000000014, w1=15.978869277390656\n",
      "SubSGD iter. 197/499: loss=5.313559727781685, w0=72.52000000000014, w1=15.923979720098881\n",
      "SubSGD iter. 198/499: loss=5.313356062413105, w0=72.52000000000014, w1=16.06803731447557\n",
      "SubSGD iter. 199/499: loss=5.314811143506558, w0=72.52000000000014, w1=15.841408236345519\n",
      "SubSGD iter. 200/499: loss=5.322701236389886, w0=72.52000000000014, w1=15.54373318303088\n",
      "SubSGD iter. 201/499: loss=5.354054095770777, w0=72.38000000000014, w1=15.240426561087169\n",
      "SubSGD iter. 202/499: loss=5.386056744689889, w0=72.10000000000014, w1=15.145725063770593\n",
      "SubSGD iter. 203/499: loss=5.384487082227096, w0=71.96000000000014, w1=15.299344379987796\n",
      "SubSGD iter. 204/499: loss=5.3485203217749335, w0=72.24000000000014, w1=15.389193985963878\n",
      "SubSGD iter. 205/499: loss=5.324654763471096, w0=72.38000000000014, w1=15.681836753059333\n",
      "SubSGD iter. 206/499: loss=5.329387447220253, w0=72.66000000000014, w1=15.418063967166093\n",
      "SubSGD iter. 207/499: loss=5.3395236989020365, w0=72.24000000000014, w1=15.530010399528665\n",
      "SubSGD iter. 208/499: loss=5.398091773088788, w0=71.68000000000013, w1=15.569082686900831\n",
      "SubSGD iter. 209/499: loss=5.352560723810171, w0=71.96000000000014, w1=16.023276189347584\n",
      "SubSGD iter. 210/499: loss=5.361340110610368, w0=71.96000000000014, w1=16.361009757965434\n",
      "SubSGD iter. 211/499: loss=5.329867439139923, w0=72.24000000000014, w1=16.235464510944933\n",
      "SubSGD iter. 212/499: loss=5.357588802131207, w0=72.10000000000014, w1=16.578197189805138\n",
      "SubSGD iter. 213/499: loss=5.365373421019417, w0=72.24000000000014, w1=16.77235369823579\n",
      "SubSGD iter. 214/499: loss=5.344734783974062, w0=72.24000000000014, w1=16.543318299902253\n",
      "SubSGD iter. 215/499: loss=5.369891012269809, w0=72.52000000000014, w1=16.87143319775303\n",
      "SubSGD iter. 216/499: loss=5.385341290877617, w0=72.52000000000014, w1=16.978540878602807\n",
      "SubSGD iter. 217/499: loss=5.379440849659499, w0=72.38000000000014, w1=16.926837164852195\n",
      "SubSGD iter. 218/499: loss=5.3610671950013655, w0=72.52000000000014, w1=16.799986372068947\n",
      "SubSGD iter. 219/499: loss=5.373979544858414, w0=72.52000000000014, w1=16.901723176987968\n",
      "SubSGD iter. 220/499: loss=5.382336781889838, w0=72.38000000000014, w1=16.948039132375985\n",
      "SubSGD iter. 221/499: loss=5.392428768381126, w0=72.38000000000014, w1=17.016181338583145\n",
      "SubSGD iter. 222/499: loss=5.375341528995849, w0=72.66000000000014, w1=16.88774815301074\n",
      "SubSGD iter. 223/499: loss=5.352709241036402, w0=72.66000000000014, w1=16.73022027328391\n",
      "SubSGD iter. 224/499: loss=5.342907257040085, w0=72.80000000000014, w1=16.617740454469963\n",
      "SubSGD iter. 225/499: loss=5.357486636687317, w0=72.80000000000014, w1=16.731965851596115\n",
      "SubSGD iter. 226/499: loss=5.360944256537167, w0=72.80000000000014, w1=16.756743205516056\n",
      "SubSGD iter. 227/499: loss=5.365074144750216, w0=72.80000000000014, w1=16.78633804426297\n",
      "SubSGD iter. 228/499: loss=5.366308203173123, w0=72.38000000000014, w1=16.81798938960541\n",
      "SubSGD iter. 229/499: loss=5.372342210085873, w0=72.24000000000014, w1=16.82471569618004\n",
      "SubSGD iter. 230/499: loss=5.3324199576000675, w0=72.38000000000014, w1=16.47114296809089\n",
      "SubSGD iter. 231/499: loss=5.335569499284671, w0=72.38000000000014, w1=16.51923700916042\n",
      "SubSGD iter. 232/499: loss=5.311185113115556, w0=72.66000000000014, w1=16.07430836601878\n",
      "SubSGD iter. 233/499: loss=5.327808043996378, w0=72.24000000000014, w1=15.961717566930963\n",
      "SubSGD iter. 234/499: loss=5.319020211627187, w0=72.38000000000014, w1=16.03384950059049\n",
      "SubSGD iter. 235/499: loss=5.374403451489403, w0=71.82000000000014, w1=16.186434036298504\n",
      "SubSGD iter. 236/499: loss=5.318954567683871, w0=72.38000000000014, w1=16.08247203502441\n",
      "SubSGD iter. 237/499: loss=5.310936410860744, w0=72.66000000000014, w1=15.992425295648944\n",
      "SubSGD iter. 238/499: loss=5.33803763609951, w0=72.10000000000014, w1=16.00749409731688\n",
      "SubSGD iter. 239/499: loss=5.313721229792647, w0=72.52000000000014, w1=15.912636828961205\n",
      "SubSGD iter. 240/499: loss=5.326536445133916, w0=72.38000000000014, w1=15.623683539172905\n",
      "SubSGD iter. 241/499: loss=5.328855817152755, w0=72.38000000000014, w1=15.552003541562964\n",
      "SubSGD iter. 242/499: loss=5.31779483915111, w0=72.52000000000014, w1=15.66046768983595\n",
      "SubSGD iter. 243/499: loss=5.327281574024736, w0=72.38000000000014, w1=15.60065539333031\n",
      "SubSGD iter. 244/499: loss=5.32286004779625, w0=72.38000000000014, w1=15.741409061563223\n",
      "SubSGD iter. 245/499: loss=5.390661797986136, w0=72.10000000000014, w1=15.112200487630293\n",
      "SubSGD iter. 246/499: loss=5.339285305967935, w0=72.66000000000014, w1=15.266132311880707\n",
      "SubSGD iter. 247/499: loss=5.332377200623658, w0=72.66000000000014, w1=15.371651256622973\n",
      "SubSGD iter. 248/499: loss=5.313720570974368, w0=72.66000000000014, w1=15.695238907583835\n",
      "SubSGD iter. 249/499: loss=5.310959270606001, w0=72.66000000000014, w1=15.999951669428333\n",
      "SubSGD iter. 250/499: loss=5.310988810147225, w0=72.66000000000014, w1=16.009677308363738\n",
      "SubSGD iter. 251/499: loss=5.31731189800112, w0=72.80000000000014, w1=16.276783736224388\n",
      "SubSGD iter. 252/499: loss=5.342625147212827, w0=72.24000000000014, w1=16.507651353474664\n",
      "SubSGD iter. 253/499: loss=5.411520136731458, w0=71.96000000000014, w1=17.00178554891474\n",
      "SubSGD iter. 254/499: loss=5.429847637634393, w0=71.68000000000013, w1=16.938973741211935\n",
      "SubSGD iter. 255/499: loss=5.438217396607228, w0=71.68000000000013, w1=17.013745042256712\n",
      "SubSGD iter. 256/499: loss=5.401464324991344, w0=71.82000000000014, w1=16.802410266200823\n",
      "SubSGD iter. 257/499: loss=5.378992462236823, w0=71.82000000000014, w1=16.32175527638922\n",
      "SubSGD iter. 258/499: loss=5.370773757882898, w0=71.82000000000014, w1=16.05858951823353\n",
      "SubSGD iter. 259/499: loss=5.366957277828917, w0=71.82000000000014, w1=15.914684501702412\n",
      "SubSGD iter. 260/499: loss=5.375095323204546, w0=71.82000000000014, w1=16.210803036983986\n",
      "SubSGD iter. 261/499: loss=5.358005850184909, w0=71.96000000000014, w1=16.24357094262528\n",
      "SubSGD iter. 262/499: loss=5.338811620480666, w0=72.10000000000014, w1=16.112407821573015\n",
      "SubSGD iter. 263/499: loss=5.335829890654725, w0=72.24000000000014, w1=16.377591218725545\n",
      "SubSGD iter. 264/499: loss=5.343237081343729, w0=72.10000000000014, w1=16.2798425378296\n",
      "SubSGD iter. 265/499: loss=5.338206787806901, w0=72.10000000000014, w1=16.034687647612202\n",
      "SubSGD iter. 266/499: loss=5.353136503158486, w0=71.96000000000014, w1=16.04814325275031\n",
      "SubSGD iter. 267/499: loss=5.33120479365408, w0=72.24000000000014, w1=16.27334847225286\n",
      "SubSGD iter. 268/499: loss=5.329254475916676, w0=72.24000000000014, w1=16.216211136000084\n",
      "SubSGD iter. 269/499: loss=5.313441494130019, w0=72.52000000000014, w1=16.090894855224743\n",
      "SubSGD iter. 270/499: loss=5.3150576865164325, w0=72.52000000000014, w1=15.825296032793528\n",
      "SubSGD iter. 271/499: loss=5.313415026016703, w0=72.52000000000014, w1=16.083813223244096\n",
      "SubSGD iter. 272/499: loss=5.344143109357271, w0=72.66000000000014, w1=16.654268366050104\n",
      "SubSGD iter. 273/499: loss=5.315320764337467, w0=72.80000000000014, w1=16.18376809500185\n",
      "SubSGD iter. 274/499: loss=5.310820188162187, w0=72.66000000000014, w1=15.954159975490303\n",
      "SubSGD iter. 275/499: loss=5.313185003931941, w0=72.80000000000014, w1=16.03887925711039\n",
      "SubSGD iter. 276/499: loss=5.338837636433275, w0=73.08000000000014, w1=16.39507635438369\n",
      "SubSGD iter. 277/499: loss=5.315154143593785, w0=72.80000000000014, w1=16.17598442100874\n",
      "SubSGD iter. 278/499: loss=5.32683968505385, w0=72.24000000000014, w1=16.020167594490474\n",
      "SubSGD iter. 279/499: loss=5.3190389560665885, w0=72.38000000000014, w1=16.030973399920125\n",
      "SubSGD iter. 280/499: loss=5.328190647184618, w0=72.24000000000014, w1=15.939508103384279\n",
      "SubSGD iter. 281/499: loss=5.319479269877664, w0=72.38000000000014, w1=15.963412731922405\n",
      "SubSGD iter. 282/499: loss=5.312871870750528, w0=72.80000000000014, w1=15.914830041951472\n",
      "SubSGD iter. 283/499: loss=5.3169776149049515, w0=72.94000000000014, w1=15.998103732073464\n",
      "SubSGD iter. 284/499: loss=5.3135430359149005, w0=72.52000000000014, w1=15.92728716909652\n",
      "SubSGD iter. 285/499: loss=5.314040597834918, w0=72.52000000000014, w1=15.891765327036744\n",
      "SubSGD iter. 286/499: loss=5.311658815064998, w0=72.66000000000014, w1=15.783061593104332\n",
      "SubSGD iter. 287/499: loss=5.329328662266498, w0=72.24000000000014, w1=15.891067569153288\n",
      "SubSGD iter. 288/499: loss=5.311765383666342, w0=72.66000000000014, w1=16.191717524811335\n",
      "SubSGD iter. 289/499: loss=5.316147532223651, w0=72.80000000000014, w1=16.222390487099034\n",
      "SubSGD iter. 290/499: loss=5.3164026431912275, w0=72.80000000000014, w1=16.23430797444069\n",
      "SubSGD iter. 291/499: loss=5.332486664705708, w0=72.80000000000014, w1=16.522178777985527\n",
      "SubSGD iter. 292/499: loss=5.325492926823033, w0=72.66000000000014, w1=16.47296900154867\n",
      "SubSGD iter. 293/499: loss=5.332352042284781, w0=72.38000000000014, w1=16.470105889591913\n",
      "SubSGD iter. 294/499: loss=5.325369977878769, w0=72.52000000000014, w1=16.446970851484505\n",
      "SubSGD iter. 295/499: loss=5.337173292135276, w0=72.38000000000014, w1=16.543727200733752\n",
      "SubSGD iter. 296/499: loss=5.327847934102312, w0=72.66000000000014, w1=16.499800812694087\n",
      "SubSGD iter. 297/499: loss=5.318382258106206, w0=72.52000000000014, w1=16.32731676519168\n",
      "SubSGD iter. 298/499: loss=5.312693839878977, w0=72.66000000000014, w1=16.23654696319123\n",
      "SubSGD iter. 299/499: loss=5.316748848298328, w0=72.52000000000014, w1=16.28999089403705\n",
      "SubSGD iter. 300/499: loss=5.3140950752485905, w0=72.52000000000014, w1=15.88820509152845\n",
      "SubSGD iter. 301/499: loss=5.313178015623155, w0=72.52000000000014, w1=16.020400302092376\n",
      "SubSGD iter. 302/499: loss=5.337128670870281, w0=73.08000000000014, w1=16.36970693824181\n",
      "SubSGD iter. 303/499: loss=5.315541368924747, w0=72.80000000000014, w1=16.194073619697193\n",
      "SubSGD iter. 304/499: loss=5.3135508990584706, w0=72.66000000000014, w1=16.261284346772527\n",
      "SubSGD iter. 305/499: loss=5.321152622288111, w0=72.38000000000014, w1=16.227023196816674\n",
      "SubSGD iter. 306/499: loss=5.314859814069276, w0=72.52000000000014, w1=16.207056052413233\n",
      "SubSGD iter. 307/499: loss=5.342685506589195, w0=72.38000000000014, w1=16.60918211767561\n",
      "SubSGD iter. 308/499: loss=5.339062344288121, w0=72.80000000000014, w1=16.582480816944184\n",
      "SubSGD iter. 309/499: loss=5.354683986448904, w0=72.80000000000014, w1=16.71188201939753\n",
      "SubSGD iter. 310/499: loss=5.328949891401842, w0=72.52000000000014, w1=16.502493219598666\n",
      "SubSGD iter. 311/499: loss=5.312165697661445, w0=72.66000000000014, w1=16.217546215954417\n",
      "SubSGD iter. 312/499: loss=5.317483434601079, w0=72.80000000000014, w1=16.284797054029\n",
      "SubSGD iter. 313/499: loss=5.328211135965489, w0=72.94000000000014, w1=16.381366644996433\n",
      "SubSGD iter. 314/499: loss=5.334788589147424, w0=73.22000000000014, w1=16.138985354021546\n",
      "SubSGD iter. 315/499: loss=5.3348153925866075, w0=73.22000000000014, w1=16.150048941864714\n",
      "SubSGD iter. 316/499: loss=5.342051649642306, w0=73.22000000000014, w1=16.298748460915785\n",
      "SubSGD iter. 317/499: loss=5.316891036477764, w0=72.94000000000014, w1=15.98845301080451\n",
      "SubSGD iter. 318/499: loss=5.312965553038773, w0=72.80000000000014, w1=15.978173706180355\n",
      "SubSGD iter. 319/499: loss=5.313835325743891, w0=72.80000000000014, w1=16.111369307416776\n",
      "SubSGD iter. 320/499: loss=5.324955678046295, w0=73.08000000000014, w1=16.005883320069927\n",
      "SubSGD iter. 321/499: loss=5.311020273848144, w0=72.66000000000014, w1=16.02003646026732\n",
      "SubSGD iter. 322/499: loss=5.317077240246943, w0=72.94000000000014, w1=15.909925405984282\n",
      "SubSGD iter. 323/499: loss=5.317222339653441, w0=72.94000000000014, w1=15.904783566414402\n",
      "SubSGD iter. 324/499: loss=5.3119035822978615, w0=72.66000000000014, w1=15.767668365860914\n",
      "SubSGD iter. 325/499: loss=5.336013318497176, w0=73.08000000000014, w1=15.558357720062435\n",
      "SubSGD iter. 326/499: loss=5.33778189185232, w0=73.08000000000014, w1=15.508833930053724\n",
      "SubSGD iter. 327/499: loss=5.3456057682740505, w0=73.08000000000014, w1=15.333371161982805\n",
      "SubSGD iter. 328/499: loss=5.333790009767321, w0=72.66000000000014, w1=15.34971891204805\n",
      "SubSGD iter. 329/499: loss=5.319580339775039, w0=72.52000000000014, w1=15.59955293571321\n",
      "SubSGD iter. 330/499: loss=5.32185551336036, w0=72.52000000000014, w1=15.557187606630249\n",
      "SubSGD iter. 331/499: loss=5.316640182690046, w0=72.52000000000014, w1=15.723914351214347\n",
      "SubSGD iter. 332/499: loss=5.319216629747113, w0=72.38000000000014, w1=16.00371158745823\n",
      "SubSGD iter. 333/499: loss=5.343745157610553, w0=72.10000000000014, w1=15.74991506772739\n",
      "SubSGD iter. 334/499: loss=5.354435778961138, w0=71.96000000000014, w1=16.104257064155448\n",
      "SubSGD iter. 335/499: loss=5.337104526831749, w0=72.24000000000014, w1=16.406319605574048\n",
      "SubSGD iter. 336/499: loss=5.350898089565231, w0=72.10000000000014, w1=16.45158545122748\n",
      "SubSGD iter. 337/499: loss=5.35515385896737, w0=71.96000000000014, w1=16.1352698837286\n",
      "SubSGD iter. 338/499: loss=5.389866916926096, w0=71.68000000000013, w1=16.08524284963689\n",
      "SubSGD iter. 339/499: loss=5.410591441143699, w0=71.54000000000013, w1=15.822822137833507\n",
      "SubSGD iter. 340/499: loss=5.367049611793004, w0=71.82000000000014, w1=15.919924013013615\n",
      "SubSGD iter. 341/499: loss=5.355486707519318, w0=71.96000000000014, w1=15.75006039083216\n",
      "SubSGD iter. 342/499: loss=5.35133583513604, w0=71.96000000000014, w1=15.906625295054333\n",
      "SubSGD iter. 343/499: loss=5.351246373513926, w0=71.96000000000014, w1=15.928879082010472\n",
      "SubSGD iter. 344/499: loss=5.371443557329587, w0=71.82000000000014, w1=16.082181092825056\n",
      "SubSGD iter. 345/499: loss=5.36629391634906, w0=71.82000000000014, w1=15.86177555764185\n",
      "SubSGD iter. 346/499: loss=5.35872068242463, w0=71.96000000000014, w1=16.268748655427437\n",
      "SubSGD iter. 347/499: loss=5.339987943943676, w0=72.24000000000014, w1=16.461760707817334\n",
      "SubSGD iter. 348/499: loss=5.335624295338592, w0=72.52000000000014, w1=16.578549777762785\n",
      "SubSGD iter. 349/499: loss=5.384222490124123, w0=71.82000000000014, w1=16.46674368771777\n",
      "SubSGD iter. 350/499: loss=5.3613498752734845, w0=71.96000000000014, w1=16.361353687449736\n",
      "SubSGD iter. 351/499: loss=5.380631620436427, w0=71.82000000000014, w1=16.36719651463835\n",
      "SubSGD iter. 352/499: loss=5.357508931224321, w0=71.96000000000014, w1=16.226068538312145\n",
      "SubSGD iter. 353/499: loss=5.375152333462872, w0=71.82000000000014, w1=16.212811043661862\n",
      "SubSGD iter. 354/499: loss=5.338501919200708, w0=72.10000000000014, w1=16.072686446642386\n",
      "SubSGD iter. 355/499: loss=5.319849397508076, w0=72.38000000000014, w1=15.906621258827075\n",
      "SubSGD iter. 356/499: loss=5.31159549418571, w0=72.66000000000014, w1=15.787043795594101\n",
      "SubSGD iter. 357/499: loss=5.331090116858891, w0=72.52000000000014, w1=15.418690971699386\n",
      "SubSGD iter. 358/499: loss=5.319871437055127, w0=72.66000000000014, w1=15.581537695999685\n",
      "SubSGD iter. 359/499: loss=5.325345566775886, w0=72.38000000000014, w1=15.660487534894145\n",
      "SubSGD iter. 360/499: loss=5.32155285754938, w0=72.38000000000014, w1=15.791663659234185\n",
      "SubSGD iter. 361/499: loss=5.31844359566397, w0=72.52000000000014, w1=15.630351788273103\n",
      "SubSGD iter. 362/499: loss=5.321506371275698, w0=72.66000000000014, w1=15.551807510785263\n",
      "SubSGD iter. 363/499: loss=5.336409442097508, w0=73.08000000000014, w1=15.547265422452474\n",
      "SubSGD iter. 364/499: loss=5.333867671505186, w0=73.08000000000014, w1=15.618440368461005\n",
      "SubSGD iter. 365/499: loss=5.323272839365074, w0=72.94000000000014, w1=15.721044002840978\n",
      "SubSGD iter. 366/499: loss=5.327849552372522, w0=72.94000000000014, w1=15.597177151162212\n",
      "SubSGD iter. 367/499: loss=5.327621548259449, w0=73.08000000000014, w1=15.83197814514809\n",
      "SubSGD iter. 368/499: loss=5.350743563670955, w0=73.36000000000014, w1=15.731434647339475\n",
      "SubSGD iter. 369/499: loss=5.341979673174009, w0=73.22000000000014, w1=15.63268043124434\n",
      "SubSGD iter. 370/499: loss=5.338119113113371, w0=73.08000000000014, w1=15.499391022373262\n",
      "SubSGD iter. 371/499: loss=5.3438471036644986, w0=73.22000000000014, w1=15.55273150189476\n",
      "SubSGD iter. 372/499: loss=5.341288824159628, w0=73.22000000000014, w1=15.662257242442038\n",
      "SubSGD iter. 373/499: loss=5.318119009151436, w0=72.94000000000014, w1=15.873008586646161\n",
      "SubSGD iter. 374/499: loss=5.343842219801054, w0=73.22000000000014, w1=15.552940591151538\n",
      "SubSGD iter. 375/499: loss=5.35244241529695, w0=73.36000000000014, w1=15.627522691409581\n",
      "SubSGD iter. 376/499: loss=5.393983896624082, w0=73.78000000000014, w1=15.615956327344785\n",
      "SubSGD iter. 377/499: loss=5.390059156161424, w0=73.64000000000014, w1=15.287833252744836\n",
      "SubSGD iter. 378/499: loss=5.375727795366394, w0=73.50000000000014, w1=15.298012610027932\n",
      "SubSGD iter. 379/499: loss=5.36591906566764, w0=73.50000000000014, w1=15.544151109721493\n",
      "SubSGD iter. 380/499: loss=5.438343753855967, w0=74.06000000000014, w1=15.730331187666236\n",
      "SubSGD iter. 381/499: loss=5.412411689972842, w0=73.92000000000014, w1=15.77251974444294\n",
      "SubSGD iter. 382/499: loss=5.378770753240293, w0=73.64000000000014, w1=15.580710615589629\n",
      "SubSGD iter. 383/499: loss=5.438564814107813, w0=74.06000000000014, w1=15.710946445308506\n",
      "SubSGD iter. 384/499: loss=5.438721720997477, w0=74.06000000000014, w1=15.697187302247444\n",
      "SubSGD iter. 385/499: loss=5.439129924537095, w0=74.06000000000014, w1=15.661391991336119\n",
      "SubSGD iter. 386/499: loss=5.412451796232778, w0=73.92000000000014, w1=15.765935707510184\n",
      "SubSGD iter. 387/499: loss=5.414425751614523, w0=73.92000000000014, w1=15.899308772152937\n",
      "SubSGD iter. 388/499: loss=5.413455488573539, w0=73.92000000000014, w1=15.677312130887149\n",
      "SubSGD iter. 389/499: loss=5.397392891996681, w0=73.78000000000014, w1=15.501341464685485\n",
      "SubSGD iter. 390/499: loss=5.371655838996252, w0=73.50000000000014, w1=15.386208639679651\n",
      "SubSGD iter. 391/499: loss=5.3572456942278714, w0=73.36000000000014, w1=15.43531963591562\n",
      "SubSGD iter. 392/499: loss=5.376927023296132, w0=73.64000000000014, w1=15.668818656785344\n",
      "SubSGD iter. 393/499: loss=5.397604683389016, w0=73.78000000000014, w1=15.494588232800417\n",
      "SubSGD iter. 394/499: loss=5.441937110775112, w0=74.06000000000014, w1=15.508666311032963\n",
      "SubSGD iter. 395/499: loss=5.466684120600947, w0=74.20000000000014, w1=15.556220040536408\n",
      "SubSGD iter. 396/499: loss=5.43799841416565, w0=74.06000000000014, w1=15.760613976483993\n",
      "SubSGD iter. 397/499: loss=5.377830424805132, w0=73.64000000000014, w1=15.622808983209278\n",
      "SubSGD iter. 398/499: loss=5.401011843970103, w0=73.64000000000014, w1=15.054045592311109\n",
      "SubSGD iter. 399/499: loss=5.432715692246433, w0=73.92000000000014, w1=15.131521818336905\n",
      "SubSGD iter. 400/499: loss=5.44397758532549, w0=73.92000000000014, w1=14.911544992870631\n",
      "SubSGD iter. 401/499: loss=5.44047272894889, w0=73.78000000000014, w1=14.65498054782816\n",
      "SubSGD iter. 402/499: loss=5.507230060528388, w0=73.78000000000014, w1=14.15724123418878\n",
      "SubSGD iter. 403/499: loss=5.48842623235051, w0=73.64000000000014, w1=14.171496135051214\n",
      "SubSGD iter. 404/499: loss=5.5399715664927545, w0=73.50000000000014, w1=13.847414077780805\n",
      "SubSGD iter. 405/499: loss=5.532753430840087, w0=73.64000000000014, w1=13.942319379020157\n",
      "SubSGD iter. 406/499: loss=5.530408915495871, w0=73.78000000000014, w1=14.032660912236766\n",
      "SubSGD iter. 407/499: loss=5.524566115350046, w0=73.50000000000014, w1=13.919303287229107\n",
      "SubSGD iter. 408/499: loss=5.483189098860748, w0=73.22000000000014, w1=14.08203821185189\n",
      "SubSGD iter. 409/499: loss=5.456411266021905, w0=73.08000000000014, w1=14.243315378117334\n",
      "SubSGD iter. 410/499: loss=5.437895564721323, w0=72.94000000000014, w1=14.384010552656823\n",
      "SubSGD iter. 411/499: loss=5.412123945758178, w0=72.94000000000014, w1=14.579586716468993\n",
      "SubSGD iter. 412/499: loss=5.385383933739402, w0=73.22000000000014, w1=14.85486035531453\n",
      "SubSGD iter. 413/499: loss=5.356733345538928, w0=72.94000000000014, w1=15.064690815159421\n",
      "SubSGD iter. 414/499: loss=5.343695753309346, w0=72.66000000000014, w1=15.212619864148502\n",
      "SubSGD iter. 415/499: loss=5.330508011814433, w0=72.66000000000014, w1=15.400668405346437\n",
      "SubSGD iter. 416/499: loss=5.3127676117836105, w0=72.80000000000014, w1=15.844334912969098\n",
      "SubSGD iter. 417/499: loss=5.312761281967605, w0=72.80000000000014, w1=15.840054981861561\n",
      "SubSGD iter. 418/499: loss=5.312780465088271, w0=72.80000000000014, w1=15.853025727742212\n",
      "SubSGD iter. 419/499: loss=5.327566705139058, w0=72.94000000000014, w1=16.37180013636431\n",
      "SubSGD iter. 420/499: loss=5.314018618726613, w0=72.66000000000014, w1=16.274784185658984\n",
      "SubSGD iter. 421/499: loss=5.310770846044187, w0=72.66000000000014, w1=15.937914509105815\n",
      "SubSGD iter. 422/499: loss=5.313330778695153, w0=72.52000000000014, w1=16.06127257142407\n",
      "SubSGD iter. 423/499: loss=5.32162494303637, w0=72.38000000000014, w1=16.240488289345638\n",
      "SubSGD iter. 424/499: loss=5.319220420873654, w0=72.38000000000014, w1=16.003129886328168\n",
      "SubSGD iter. 425/499: loss=5.316199272348902, w0=72.52000000000014, w1=16.277432256897082\n",
      "SubSGD iter. 426/499: loss=5.318963106373008, w0=72.38000000000014, w1=16.084756589776998\n",
      "SubSGD iter. 427/499: loss=5.312439216640327, w0=72.66000000000014, w1=16.2291977475549\n",
      "SubSGD iter. 428/499: loss=5.319325739453485, w0=72.38000000000014, w1=16.16723248094403\n",
      "SubSGD iter. 429/499: loss=5.326875153197773, w0=72.24000000000014, w1=16.016532844351232\n",
      "SubSGD iter. 430/499: loss=5.319049963591593, w0=72.38000000000014, w1=16.10799552825155\n",
      "SubSGD iter. 431/499: loss=5.35156251020578, w0=71.96000000000014, w1=15.96604597889951\n",
      "SubSGD iter. 432/499: loss=5.331164235953179, w0=72.24000000000014, w1=16.272434362531072\n",
      "SubSGD iter. 433/499: loss=5.326793394088696, w0=72.38000000000014, w1=16.36114711270319\n",
      "SubSGD iter. 434/499: loss=5.321675184747781, w0=72.52000000000014, w1=16.388605852961042\n",
      "SubSGD iter. 435/499: loss=5.326880657501389, w0=72.38000000000014, w1=16.36314121294855\n",
      "SubSGD iter. 436/499: loss=5.330855338331737, w0=72.80000000000014, w1=16.507218756694265\n",
      "SubSGD iter. 437/499: loss=5.333121659156911, w0=73.08000000000014, w1=16.31022326587108\n",
      "SubSGD iter. 438/499: loss=5.316539396178154, w0=72.94000000000014, w1=15.94247225029114\n",
      "SubSGD iter. 439/499: loss=5.326244678030989, w0=73.08000000000014, w1=16.11131114067262\n",
      "SubSGD iter. 440/499: loss=5.326113172097508, w0=73.08000000000014, w1=15.899910349708147\n",
      "SubSGD iter. 441/499: loss=5.318282156704939, w0=72.94000000000014, w1=15.867227180873586\n",
      "SubSGD iter. 442/499: loss=5.328913998851507, w0=73.08000000000014, w1=15.785190922472504\n",
      "SubSGD iter. 443/499: loss=5.328162036985994, w0=73.08000000000014, w1=15.811837945836933\n",
      "SubSGD iter. 444/499: loss=5.336767123703213, w0=73.22000000000014, w1=15.939750651398652\n",
      "SubSGD iter. 445/499: loss=5.348031820589387, w0=73.36000000000014, w1=15.97387204310331\n",
      "SubSGD iter. 446/499: loss=5.346636084156655, w0=73.36000000000014, w1=16.098654773526377\n",
      "SubSGD iter. 447/499: loss=5.324833478903042, w0=73.08000000000014, w1=16.034910185260497\n",
      "SubSGD iter. 448/499: loss=5.316914019256491, w0=72.94000000000014, w1=15.991014854426226\n",
      "SubSGD iter. 449/499: loss=5.350603647121972, w0=73.36000000000014, w1=16.248255034470496\n",
      "SubSGD iter. 450/499: loss=5.336128705813387, w0=73.22000000000014, w1=15.998200230509632\n",
      "SubSGD iter. 451/499: loss=5.31693147403667, w0=72.94000000000014, w1=15.992960503288192\n",
      "SubSGD iter. 452/499: loss=5.31819650606892, w0=72.80000000000014, w1=16.31810812752925\n",
      "SubSGD iter. 453/499: loss=5.324836458718718, w0=72.52000000000014, w1=16.438593813419242\n",
      "SubSGD iter. 454/499: loss=5.316050658051224, w0=72.80000000000014, w1=16.217865018301733\n",
      "SubSGD iter. 455/499: loss=5.3110210845501, w0=72.66000000000014, w1=16.02030337688761\n",
      "SubSGD iter. 456/499: loss=5.314083974186522, w0=72.80000000000014, w1=16.12599154737585\n",
      "SubSGD iter. 457/499: loss=5.3389840303435685, w0=73.22000000000014, w1=15.760930686462638\n",
      "SubSGD iter. 458/499: loss=5.328944076108241, w0=73.08000000000014, w1=15.78412508469585\n",
      "SubSGD iter. 459/499: loss=5.312952599279782, w0=72.80000000000014, w1=15.82138599205232\n",
      "SubSGD iter. 460/499: loss=5.318798735930242, w0=72.80000000000014, w1=15.676155974456178\n",
      "SubSGD iter. 461/499: loss=5.335986358226732, w0=73.22000000000014, w1=16.01123269194277\n",
      "SubSGD iter. 462/499: loss=5.317173655400459, w0=72.94000000000014, w1=16.011312350872196\n",
      "SubSGD iter. 463/499: loss=5.312990738279955, w0=72.80000000000014, w1=15.99520281051528\n",
      "SubSGD iter. 464/499: loss=5.3132104985155, w0=72.52000000000014, w1=16.029091208260265\n",
      "SubSGD iter. 465/499: loss=5.316089986575858, w0=72.52000000000014, w1=15.757832636882947\n",
      "SubSGD iter. 466/499: loss=5.313387350272906, w0=72.52000000000014, w1=16.07640848570094\n",
      "SubSGD iter. 467/499: loss=5.310851989932586, w0=72.66000000000014, w1=15.91765528298419\n",
      "SubSGD iter. 468/499: loss=5.311376261304086, w0=72.66000000000014, w1=16.137242256924427\n",
      "SubSGD iter. 469/499: loss=5.314571473081347, w0=72.52000000000014, w1=16.183841957667354\n",
      "SubSGD iter. 470/499: loss=5.326848677444838, w0=72.52000000000014, w1=16.47018861661751\n",
      "SubSGD iter. 471/499: loss=5.31152343676814, w0=72.66000000000014, w1=16.17125102753381\n",
      "SubSGD iter. 472/499: loss=5.324543183731088, w0=72.66000000000014, w1=16.462148089229668\n",
      "SubSGD iter. 473/499: loss=5.313566552676665, w0=72.66000000000014, w1=16.261736158697467\n",
      "SubSGD iter. 474/499: loss=5.329388983238973, w0=72.38000000000014, w1=16.418743792261584\n",
      "SubSGD iter. 475/499: loss=5.361798092490103, w0=72.24000000000014, w1=16.743134812684712\n",
      "SubSGD iter. 476/499: loss=5.346559140545844, w0=72.10000000000014, w1=16.36071397946891\n",
      "SubSGD iter. 477/499: loss=5.3485639556215885, w0=72.24000000000014, w1=16.60012879690442\n",
      "SubSGD iter. 478/499: loss=5.3621204330604515, w0=72.24000000000014, w1=16.745868461410453\n",
      "SubSGD iter. 479/499: loss=5.340608630339197, w0=72.52000000000014, w1=16.623062298976745\n",
      "SubSGD iter. 480/499: loss=5.321567422747992, w0=72.52000000000014, w1=16.38668824478332\n",
      "SubSGD iter. 481/499: loss=5.3554316032077445, w0=72.24000000000014, w1=16.680128909397418\n",
      "SubSGD iter. 482/499: loss=5.335355639627634, w0=72.52000000000014, w1=16.575714733642215\n",
      "SubSGD iter. 483/499: loss=5.324505510652548, w0=72.80000000000014, w1=16.448987884692023\n",
      "SubSGD iter. 484/499: loss=5.3196830373983826, w0=72.80000000000014, w1=16.369075664824337\n",
      "SubSGD iter. 485/499: loss=5.327548616313005, w0=73.08000000000014, w1=16.160950934078283\n",
      "SubSGD iter. 486/499: loss=5.3110134549971715, w0=72.66000000000014, w1=16.017791412451572\n",
      "SubSGD iter. 487/499: loss=5.334397673240825, w0=72.94000000000014, w1=16.473205147780803\n",
      "SubSGD iter. 488/499: loss=5.37459542323869, w0=73.22000000000014, w1=16.65177459438063\n",
      "SubSGD iter. 489/499: loss=5.394609516935966, w0=73.36000000000014, w1=16.701394580586747\n",
      "SubSGD iter. 490/499: loss=5.3602525764381905, w0=73.36000000000014, w1=16.371378451624903\n",
      "SubSGD iter. 491/499: loss=5.329999981330882, w0=73.08000000000014, w1=16.250498532082574\n",
      "SubSGD iter. 492/499: loss=5.370224106157323, w0=73.08000000000014, w1=16.707606568266538\n",
      "SubSGD iter. 493/499: loss=5.324853917042664, w0=73.08000000000014, w1=16.04334638449327\n",
      "SubSGD iter. 494/499: loss=5.337376144404394, w0=73.22000000000014, w1=15.883992496401364\n",
      "SubSGD iter. 495/499: loss=5.346641850741266, w0=73.36000000000014, w1=16.098139224776652\n",
      "SubSGD iter. 496/499: loss=5.346569059627603, w0=73.36000000000014, w1=16.13349163796977\n",
      "SubSGD iter. 497/499: loss=5.3348485598248825, w0=73.22000000000014, w1=16.163739298974363\n",
      "SubSGD iter. 498/499: loss=5.324840900214864, w0=73.08000000000014, w1=16.037973461383753\n",
      "SubSGD iter. 499/499: loss=5.313172152298409, w0=72.80000000000014, w1=16.03744671164742\n",
      "SubSGD: execution time=0.018 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 10\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6129509c2c7c4f70b63942faf327da69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=1, min=1), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
